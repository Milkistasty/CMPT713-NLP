{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prefixtune: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gouttham/NLP_commit/nlp3/prefixtune/env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/gouttham/NLP_commit/nlp3/prefixtune/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from prefixtune import *\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0||  __________________________________________________________________________   It's been a busy day for me this week, and I've been working hard to make sure you're on the right track. I'm going to take a look at some of the most popular ways to make your\n",
      "1||  _______________   I’ve been waiting for the last few days for the release of the latest version of Windows Phone 8.1.0.1, but I’m not sure what it means to be a Windows Phone user\n",
      "2||  __________________________________________   The U.S. Department of Justice (DOJ) announced today that the Justice Department has filed a lawsuit against the Federal Bureau of Investigation (FBI) for the unlawful use of a private email server in the United States\n",
      "3||  _______________________________________________________________________________   This is the first in a series of blog posts on the subject of a new book, “The Rise and Fall of the American Civil War.” The following is an excerpt from the book The Rise and\n",
      "4||  _______________   The following is a list of things you should know about the world's most important health care system:  1. What is your health care plan? The Affordable Care Act (ACA) requires that all health care providers\n",
      "5||  __________________________________________________________________________________   I’ve been working on a new project for the past couple of years, and I’m excited to share it with you. It’s been a long time since I started this project, and\n",
      "6||  ___________________________________________________________________________   This is the first in a series of blog posts on this topic.  In the past few weeks, I have been working on a new version of the Linux kernel for Linux. The Linux kernel has been updated to\n",
      "7||  ___________________________________________________________________________   The U.S. Department of Homeland Security (DHS) has issued a new report to the Department of Justice (DOJ) and the Federal Bureau of Investigation (FBI) in the wake of the 9/11\n",
      "8||  _______________________________________________________________________________   I've been working on this blog for a while now, but I wanted to share with you a little bit about the history of the internet. I've been writing about the internet for over a year now, and I\n",
      "9||   I’ve been looking for a new way to get rid of all the annoying things you have to do to keep up with your daily life.   If you’re looking for an easy way to improve your life, you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "basemodel = 'distilgpt2'\n",
    "table_to_text = TableToText(\"peft\", basemodel=basemodel)\n",
    "model = AutoModelForCausalLM.from_pretrained(basemodel)\n",
    "decoder_output = table_to_text.decode(model, '../data/input/small.txt')\n",
    "print(\"\\n\".join(decoder_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the warnings from the transformers library. They are expected to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `bleu.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try 1: epochs 3; prefixprojection : False\n",
    "dev.out score: 0.9345\n",
    "small.out score: 1.1543\n",
    "\n",
    "Try 2: epochs 3; prefixprojection : True\n",
    "dev.out score: 16.2812\n",
    "small.out score: 16.8922\n",
    "\n",
    "Try 3: epochs 3; prefixprojection : True; no_repeat_ngram_size = 3 (Got it from wwa118)\n",
    "small.out score: 22.1565\n",
    "dev.out score: 31.1741\n",
    "\n",
    "Try 4: epochs 3; prefixprojection : True; no_repeat_ngram_size = 3 (Got it from wwa118); num_sequences=5; selection stratergy based on score\n",
    "small.out score: 22.7204\n",
    "dev.out score: 29.9943\n",
    "\n",
    "Try 5: epochs 3; prefixprojection : True; no_repeat_ngram_size = 3 (Got it from wwa118); num_sequences=5; selection stratergy based on length of the text\n",
    "small.out score: 20.8834\n",
    "dev.out score: 30.5553"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "selecting based on scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(basemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Convert the following table into English text: '\n",
    "src = 'name : Alimentum | area : city centre | family friendly : no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = prompt + src + ' ' + tokenizer.bos_token + ' '\n",
    "inputs = tokenizer(prompt + src + ' ' + tokenizer.bos_token + ' ', return_tensors=\"pt\")\n",
    "prediction = None\n",
    "\n",
    "num_sequences = 5\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=50,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        num_beams=5,\n",
    "        top_p=0.9,\n",
    "        temperature=1.0,\n",
    "        num_return_sequences=num_sequences,\n",
    "        no_repeat_ngram_size = 3,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "    # TODO you may want to generate more than one sequence and choose the best one!\n",
    "    # text = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4093, -1.4414, -1.4428, -1.4512, -1.4558])\n"
     ]
    }
   ],
   "source": [
    "sequences_scores = outputs.sequences_scores\n",
    "print(sequences_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.batch_decode([outputs.sequences[torch.argmax(sequences_scores).item()]], skip_special_tokens=True)\n",
    "text = text[0]\n",
    "input_text = input_text.replace(tokenizer.bos_token,\"\")\n",
    "generated_text = text[len(input_text):] if text.startswith(input_text) else text\n",
    "generated_text = generated_text.lstrip().replace(prompt + src, \"\").replace(\"\\n\", \" \")\n",
    "generated_text = generated_text.strip().replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.startswith(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting based on lenght of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(basemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Convert the following table into English text: '\n",
    "src = 'name : Alimentum | area : city centre | family friendly : no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = prompt + src + ' ' + tokenizer.bos_token + ' '\n",
    "inputs = tokenizer(prompt + src + ' ' + tokenizer.bos_token + ' ', return_tensors=\"pt\")\n",
    "prediction = None\n",
    "\n",
    "num_sequences = 5\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=50,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        num_beams=5,\n",
    "        top_p=0.9,\n",
    "        temperature=1.0,\n",
    "        num_return_sequences=num_sequences,\n",
    "        no_repeat_ngram_size = 3,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "    # TODO you may want to generate more than one sequence and choose the best one!\n",
    "    # text = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)\n",
    "text = max(text, key=lambda i: len(i.split(' ')))\n",
    "input_text = input_text.replace(tokenizer.bos_token,\"\")\n",
    "generated_text = text[len(input_text):] if text.startswith(input_text) else text\n",
    "generated_text = generated_text.lstrip().replace(prompt + src, \"\").replace(\"\\n\", \" \")\n",
    "generated_text = generated_text.strip().replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'___________________________________________________________________________   We’ve been around for a while now, and I’m sure it’s a good time to give you a look at some of the most important and most important things to know about the internet'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
