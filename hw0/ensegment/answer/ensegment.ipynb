{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOUTTHAM (USERNAME : GNA23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  choose spain\n",
      "output :  this is a test\n",
      "output :  who represents\n",
      "output :  experts exchange\n",
      "output :  speed of art\n",
      "output :  unclimatechangebody\n",
      "output :  we are the people\n",
      "output :  mentionyourfaves\n",
      "output :  now playing\n",
      "output :  the walking dead\n",
      "output :  follow me\n",
      "output :  we are the people\n",
      "output :  mentionyourfaves\n",
      "output :  check domain\n",
      "output :  big rock\n",
      "output :  name cheap\n",
      "output :  apple domains\n",
      "output :  honesty hour\n",
      "output :  being human\n",
      "output :  follow back\n",
      "output :  social media\n",
      "output :  30secondstoearth\n",
      "output :  current ratesoughttogodown\n",
      "output :  this is insane\n",
      "output :  what is my name\n",
      "output :  is it time\n",
      "output :  let us go\n",
      "output :  me too\n",
      "output :  nowthatcherisdead\n",
      "output :  advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        # print(\"input : \",line)\n",
    "        print(\"output : \",\" \".join(segmenter.segment(line.strip())))\n",
    "        # print(\"******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 'owtobreakupinfivewords'),\n",
       " ('ho', 'wtobreakupinfivewords'),\n",
       " ('how', 'tobreakupinfivewords'),\n",
       " ('howt', 'obreakupinfivewords'),\n",
       " ('howto', 'breakupinfivewords'),\n",
       " ('howtob', 'reakupinfivewords'),\n",
       " ('howtobr', 'eakupinfivewords'),\n",
       " ('howtobre', 'akupinfivewords'),\n",
       " ('howtobrea', 'kupinfivewords'),\n",
       " ('howtobreak', 'upinfivewords'),\n",
       " ('howtobreaku', 'pinfivewords'),\n",
       " ('howtobreakup', 'infivewords'),\n",
       " ('howtobreakupi', 'nfivewords'),\n",
       " ('howtobreakupin', 'fivewords'),\n",
       " ('howtobreakupinf', 'ivewords'),\n",
       " ('howtobreakupinfi', 'vewords'),\n",
       " ('howtobreakupinfiv', 'ewords'),\n",
       " ('howtobreakupinfive', 'words'),\n",
       " ('howtobreakupinfivew', 'ords'),\n",
       " ('howtobreakupinfivewo', 'rds')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding how the splits function works and why L=20 \n",
    "segmenter.splits(\"howtobreakupinfivewords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging a failed case \"mentionyourfaves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mentionyourfaves']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysing the failure use\n",
    "segmenter = Segment(Pw)\n",
    "segmenter.segment(\"mentionyourfaves\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider the below part\n",
    "> Pwords ['i', 'on', 'your', 'faves'] 1.0426721292078651e-13\n",
    "Pwords ['io', 'n', 'your', 'faves'] 2.3336633561979745e-17\n",
    "Pwords ['ion', 'your', 'faves'] 6.396854426375323e-14\n",
    "Pwords ['iony', 'our', 'faves'] 2.566058281050438e-21\n",
    "Pwords ['ionyo', 'ur', 'faves'] 2.0459993554349096e-23\n",
    "Pwords ['ionyou', 'r', 'faves'] 8.312401592220777e-22\n",
    "Pwords ['ionyour', 'faves'] 1.5110377615957641e-18\n",
    "Pwords ['ionyourf', 'aves'] 1.1359504127205585e-18\n",
    "Pwords ['ionyourfa', 'ves'] 9.960822863188322e-19\n",
    "Pwords ['ionyourfav', 'es'] 9.011381114069015e-17\n",
    "Pwords ['ionyourfave', 's'] 1.6338252631752372e-15\n",
    "Pwords ['ionyourfaves'] 1.7003210642847526e-12\n",
    "[['t', 'ionyourfaves'], ['ti', 'on', 'your', 'faves'], ['tio', 'n', 'your', 'faves'], ['tion', 'your', 'faves'], ['tiony', 'our', 'faves'], ['tionyo', 'ur', 'faves'], ['tionyou', 'r', 'faves'], ['tionyour', 'faves'], ['tionyourf', 'aves'], ['tionyourfa', 'ves'], ['tionyourfav', 'es'], ['tionyourfave', 's'], ['tionyourfaves']]\n",
    "Pwords ['t', 'ionyourfaves'] 1.1230388491313186e-15\n",
    "\n",
    "It starts to go wront because of the following Probablities\n",
    "- Pwords ['ionyourfaves'] 1.7003210642847526e-12\n",
    "- Pwords ['i', 'on', 'your', 'faves'] 1.0426721292078651e-13\n",
    "\n",
    "Since we are assigning (lambda k, N: 1./N) for words not present in ngram, the above distribution is messed up. to handle this, i am assigning '0' to the words that are not present in ngrams.\n",
    "\n",
    "\n",
    ">After this the \n",
    "dev score increased from 0.82 to 0.98\n",
    "test score increased from 0.13 to 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensegment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not accounted for integers\n",
    "def return_zero_for_missing_word(k,n):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  mention your faves\n",
      "output :  m e n t i o n y o u r 5 faves\n"
     ]
    }
   ],
   "source": [
    "# Analysing the failure use\n",
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"),missingfn=return_zero_for_missing_word)\n",
    "# Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "split_list = segmenter.segment(\"mentionyourfaves\".strip())\n",
    "print(\"output : \",\" \".join(split_list))\n",
    "\n",
    "split_list = segmenter.segment(\"mentionyour5faves\".strip())\n",
    "print(\"output : \",\" \".join(split_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integer is messing with the probablities assigned, So trying our different probablities for integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalizing based on the length of the unknown word\n",
    "def return_scaled_prob_for_missing_word_with_int_handling(key,N):\n",
    "    try:\n",
    "        int(key)\n",
    "        return 1e-10\n",
    "    except:\n",
    "        return (1./N)**len(key)\n",
    "\n",
    "# zero if the words are not present\n",
    "def return_zero_prob_for_missing_word_with_int_handling(key,N):\n",
    "    try:\n",
    "        int(key)\n",
    "        return 1e-10\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  mention your faves\n",
      "output :  mention your 5 faves\n"
     ]
    }
   ],
   "source": [
    "# Analysing the failure use\n",
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"),missingfn=return_zero_prob_for_missing_word_with_int_handling)\n",
    "# Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "split_list = segmenter.segment(\"mentionyourfaves\".strip())\n",
    "print(\"output : \",\" \".join(split_list))\n",
    "\n",
    "split_list = segmenter.segment(\"mentionyour5faves\".strip())\n",
    "print(\"output : \",\" \".join(split_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the above methods seems to be working fine.\n",
    "\n",
    "dev.out score: 1.00\n",
    "test.out score: 0.97\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
