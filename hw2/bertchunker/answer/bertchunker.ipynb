{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bertchunker: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1027/1027 [02:18<00:00,  7.44it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = FinetuneTagger(os.path.join('..', 'data', 'default_chunker'), modelsuffix='.pt') #Call default.py with model file: data/default_chunker.\n",
    "decoder_output = chunker.decode(os.path.join('..', 'data', 'input', 'dev.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the warnings from the transformers library. They are expected to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11845 phrases; correct: 10756.\n",
      "accuracy:  94.32%; (non-O)\n",
      "accuracy:  94.41%; precision:  90.81%; recall:  90.42%; FB1:  90.61\n",
      "             ADJP: precision:  72.27%; recall:  70.35%; FB1:  71.30  220\n",
      "             ADVP: precision:  73.00%; recall:  73.37%; FB1:  73.18  400\n",
      "            CONJP: precision:  71.43%; recall:  71.43%; FB1:  71.43  7\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  90.61%; recall:  91.28%; FB1:  90.94  6283\n",
      "               PP: precision:  97.00%; recall:  94.14%; FB1:  95.55  2369\n",
      "              PRT: precision:  79.55%; recall:  77.78%; FB1:  78.65  44\n",
      "             SBAR: precision:  93.05%; recall:  73.42%; FB1:  82.08  187\n",
      "               VP: precision:  89.94%; recall:  91.15%; FB1:  90.54  2335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90.80624736175602, 90.41694687289845, 90.61117897308453)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "sys.path.append('..')\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('..', 'data', 'reference', 'dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerModel:\n\tMissing key(s) in state_dict: \"classification_head.weight\", \"classification_head.bias\". \n\tUnexpected key(s) in state_dict: \"classification_head.0.weight\", \"classification_head.0.bias\", \"classification_head.2.weight\", \"classification_head.2.bias\", \"classification_head.4.weight\", \"classification_head.4.bias\", \"classification_head.6.weight\", \"classification_head.6.bias\", \"classification_head.8.weight\", \"classification_head.8.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m chunker \u001b[38;5;241m=\u001b[39m FinetuneTagger(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunker\u001b[39m\u001b[38;5;124m'\u001b[39m), modelsuffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdev.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp24/nlpclass-1247-g-nlp_for_cv/hw2/bertchunker/answer/default.py:238\u001b[0m, in \u001b[0;36mFinetuneTagger.decode\u001b[0;34m(self, inputfile)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mix_to_tag \u001b[38;5;241m=\u001b[39m saved_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mix_to_tag\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    237\u001b[0m model \u001b[38;5;241m=\u001b[39m TransformerModel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasemodel, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag_to_ix), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 238\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# use the model for evaluation not training\u001b[39;00m\n\u001b[1;32m    240\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/nlp24/nlpclass-1247-g-nlp_for_cv/hw2/bertchunker/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TransformerModel:\n\tMissing key(s) in state_dict: \"classification_head.weight\", \"classification_head.bias\". \n\tUnexpected key(s) in state_dict: \"classification_head.0.weight\", \"classification_head.0.bias\", \"classification_head.2.weight\", \"classification_head.2.bias\", \"classification_head.4.weight\", \"classification_head.4.bias\", \"classification_head.6.weight\", \"classification_head.6.bias\", \"classification_head.8.weight\", \"classification_head.8.bias\". "
     ]
    }
   ],
   "source": [
    "chunker = FinetuneTagger(os.path.join('..', 'data', 'chunker'), modelsuffix='.pt')\n",
    "decoder_output = chunker.decode(os.path.join('..', 'data', 'input', 'dev.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "sys.path.append('..')\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('..', 'data', 'reference', 'dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)\n",
    "\n",
    "\n",
    "\n",
    "#FB1 Score: 94.18, aug_ratio: 0.25% \n",
    "#FB1 Score: 94.31, aug_ratio: 0.2% \n",
    "#FB1 Score: 94.23, aug_ratio: 0.15% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = FinetuneTagger(os.path.join('..', 'data', 'chunker'), modelsuffix='.pt')\n",
    "decoder_output = chunker.decode(os.path.join('..', 'data', 'input', 'dev.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "sys.path.append('..')\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('..', 'data', 'reference', 'dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)\n",
    "\n",
    "\n",
    "\n",
    "#FB1 Score: 94.18, aug_ratio: 0.25% \n",
    "#FB1 Score: 94.31, aug_ratio: 0.2% \n",
    "#FB1 Score: 94.23, aug_ratio: 0.15% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
