{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analogy: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from analogy import *\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/wenhe/nlp-class-hw/analogy/venv/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/wenhe/nlp-class-hw/analogy/venv/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/wenhe/nlp-class-hw/analogy/venv/lib/python3.11/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/wenhe/nlp-class-hw/analogy/venv/lib/python3.11/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in /Users/wenhe/nlp-class-hw/analogy/venv/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/wenhe/nlp-class-hw/analogy/venv/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the glove 100d model trained on the gigaword corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gigaword = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the output on the word analogy task by reading the dev set and using vector arithmetic over the word vectors for the first 10 lines in the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens-greece+iraq=baghdad\n",
      "athens-greece+thailand=bangkok\n",
      "athens-greece+china=beijing\n",
      "athens-greece+germany=berlin\n",
      "athens-greece+switzerland=zurich\n",
      "athens-greece+egypt=cairo\n",
      "athens-greece+australia=sydney\n",
      "athens-greece+vietnam=hanoi\n",
      "athens-greece+cuba=havana\n",
      "athens-greece+finland=helsinki\n",
      "[': capital-common-countries', 'baghdad', 'bangkok', 'beijing', 'berlin', 'zurich', 'cairo', 'sydney', 'hanoi', 'havana', 'helsinki']\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "with open(os.path.join('../data', 'input', 'dev.txt')) as fh:\n",
    "    for i, line in enumerate(fh):\n",
    "        if i > 10:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line[0] == ':':\n",
    "            output.append(line)\n",
    "            continue\n",
    "        (a, b, c) = line.split()\n",
    "        results = model_gigaword.most_similar(positive=[a.lower(), c.lower()], negative=[b.lower()])\n",
    "        print(f\"{a.lower()}-{b.lower()}+{c.lower()}={results[0][0]}\")\n",
    "        output.append(results[0][0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=80.00\n"
     ]
    }
   ],
   "source": [
    "# Load the model architecture\n",
    "current_dir = os.path.dirname(os.curdir)\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "# python_dir = os.path.join(parent_dir, 'answer')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from analogy_check import precision\n",
    "with open(os.path.join('../data','reference','dev.out'), 'rt') as refh:\n",
    "    ref_data = [str(x).strip() for x in refh.read().splitlines()]\n",
    "print(\"Score={:.2f}\".format(100*precision(ref_data, output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: the\n",
      "Vector: [-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n",
      "\n",
      "Word: ,\n",
      "Vector: [-0.10767    0.11053    0.59812   -0.54361    0.67396    0.10663\n",
      "  0.038867   0.35481    0.06351   -0.094189   0.15786   -0.81665\n",
      "  0.14172    0.21939    0.58505   -0.52158    0.22783   -0.16642\n",
      " -0.68228    0.3587     0.42568    0.19021    0.91963    0.57555\n",
      "  0.46185    0.42363   -0.095399  -0.42749   -0.16567   -0.056842\n",
      " -0.29595    0.26037   -0.26606   -0.070404  -0.27662    0.15821\n",
      "  0.69825    0.43081    0.27952   -0.45437   -0.33801   -0.58184\n",
      "  0.22364   -0.5778    -0.26862   -0.20425    0.56394   -0.58524\n",
      " -0.14365   -0.64218    0.0054697 -0.35248    0.16162    1.1796\n",
      " -0.47674   -2.7553    -0.1321    -0.047729   1.0655     1.1034\n",
      " -0.2208     0.18669    0.13177    0.15117    0.7131    -0.35215\n",
      "  0.91348    0.61783    0.70992    0.23955   -0.14571   -0.37859\n",
      " -0.045959  -0.47368    0.2385     0.20536   -0.18996    0.32507\n",
      " -1.1112    -0.36341    0.98679   -0.084776  -0.54008    0.11726\n",
      " -1.0194    -0.24424    0.12771    0.013884   0.080374  -0.35414\n",
      "  0.34951   -0.7226     0.37549    0.4441    -0.99059    0.61214\n",
      " -0.35111   -0.83155    0.45293    0.082577 ]\n",
      "\n",
      "Word: .\n",
      "Vector: [-0.33979    0.20941    0.46348   -0.64792   -0.38377    0.038034\n",
      "  0.17127    0.15978    0.46619   -0.019169   0.41479   -0.34349\n",
      "  0.26872    0.04464    0.42131   -0.41032    0.15459    0.022239\n",
      " -0.64653    0.25256    0.043136  -0.19445    0.46516    0.45651\n",
      "  0.68588    0.091295   0.21875   -0.70351    0.16785   -0.35079\n",
      " -0.12634    0.66384   -0.2582     0.036542  -0.13605    0.40253\n",
      "  0.14289    0.38132   -0.12283   -0.45886   -0.25282   -0.30432\n",
      " -0.11215   -0.26182   -0.22482   -0.44554    0.2991    -0.85612\n",
      " -0.14503   -0.49086    0.0082973 -0.17491    0.27524    1.4401\n",
      " -0.21239   -2.8435    -0.27958   -0.45722    1.6386     0.78808\n",
      " -0.55262    0.65       0.086426   0.39012    1.0632    -0.35379\n",
      "  0.48328    0.346      0.84174    0.098707  -0.24213   -0.27053\n",
      "  0.045287  -0.40147    0.11395    0.0062226  0.036673   0.018518\n",
      " -1.0213    -0.20806    0.64072   -0.068763  -0.58635    0.33476\n",
      " -1.1432    -0.1148    -0.25091   -0.45907   -0.096819  -0.17946\n",
      " -0.063351  -0.67412   -0.068895   0.53604   -0.87773    0.31802\n",
      " -0.39242   -0.23394    0.47298   -0.028803 ]\n",
      "\n",
      "Word: of\n",
      "Vector: [-0.1529   -0.24279   0.89837   0.16996   0.53516   0.48784  -0.58826\n",
      " -0.17982  -1.3581    0.42541   0.15377   0.24215   0.13474   0.41193\n",
      "  0.67043  -0.56418   0.42985  -0.012183 -0.11677   0.31781   0.054177\n",
      " -0.054273  0.35516  -0.30241   0.31434  -0.33846   0.71715  -0.26855\n",
      " -0.15837  -0.47467   0.051581 -0.33252   0.15003  -0.1299   -0.54617\n",
      " -0.37843   0.64261   0.82187  -0.080006  0.078479 -0.96976  -0.57741\n",
      "  0.56491  -0.39873  -0.057099  0.19743   0.065706 -0.48092  -0.20125\n",
      " -0.40834   0.39456  -0.02642  -0.11838   1.012    -0.53171  -2.7474\n",
      " -0.042981 -0.74849   1.7574    0.59085   0.04885   0.78267   0.38497\n",
      "  0.42097   0.67882   0.10337   0.6328   -0.026595  0.58647  -0.44332\n",
      "  0.33057  -0.12022  -0.55645   0.073611  0.20915   0.43395  -0.012761\n",
      "  0.089874 -1.7991    0.084808  0.77112   0.63105  -0.90685   0.60326\n",
      " -1.7515    0.18596  -0.50687  -0.70203   0.66578  -0.81304   0.18712\n",
      " -0.018488 -0.26757   0.727    -0.59363  -0.34839  -0.56094  -0.591\n",
      "  1.0039    0.20664 ]\n",
      "\n",
      "Word: to\n",
      "Vector: [-1.8970e-01  5.0024e-02  1.9084e-01 -4.9184e-02 -8.9737e-02  2.1006e-01\n",
      " -5.4952e-01  9.8377e-02 -2.0135e-01  3.4241e-01 -9.2677e-02  1.6100e-01\n",
      " -1.3268e-01 -2.8160e-01  1.8737e-01 -4.2959e-01  9.6039e-01  1.3972e-01\n",
      " -1.0781e+00  4.0518e-01  5.0539e-01 -5.5064e-01  4.8440e-01  3.8044e-01\n",
      " -2.9055e-03 -3.4942e-01 -9.9696e-02 -7.8368e-01  1.0363e+00 -2.3140e-01\n",
      " -4.7121e-01  5.7126e-01 -2.1454e-01  3.5958e-01 -4.8319e-01  1.0875e+00\n",
      "  2.8524e-01  1.2447e-01 -3.9248e-02 -7.6732e-02 -7.6343e-01 -3.2409e-01\n",
      " -5.7490e-01 -1.0893e+00 -4.1811e-01  4.5120e-01  1.2112e-01 -5.1367e-01\n",
      " -1.3349e-01 -1.1378e+00 -2.8768e-01  1.6774e-01  5.5804e-01  1.5387e+00\n",
      "  1.8859e-02 -2.9721e+00 -2.4216e-01 -9.2495e-01  2.1992e+00  2.8234e-01\n",
      " -3.4780e-01  5.1621e-01 -4.3387e-01  3.6852e-01  7.4573e-01  7.2102e-02\n",
      "  2.7931e-01  9.2569e-01 -5.0336e-02 -8.5856e-01 -1.3580e-01 -9.2551e-01\n",
      " -3.3991e-01 -1.0394e+00 -6.7203e-02 -2.1379e-01 -4.7690e-01  2.1377e-01\n",
      " -8.4008e-01  5.2536e-02  5.9298e-01  2.9604e-01 -6.7644e-01  1.3916e-01\n",
      " -1.5504e+00 -2.0765e-01  7.2220e-01  5.2056e-01 -7.6221e-02 -1.5194e-01\n",
      " -1.3134e-01  5.8617e-02 -3.1869e-01 -6.1419e-01 -6.2393e-01 -4.1548e-01\n",
      " -3.8175e-02 -3.9804e-01  4.7647e-01 -1.5983e-01]\n",
      "\n",
      "Word: and\n",
      "Vector: [-0.071953  0.23127   0.023731 -0.50638   0.33923   0.1959   -0.32943\n",
      "  0.18364  -0.18057   0.28963   0.20448  -0.5496    0.27399   0.58327\n",
      "  0.20468  -0.49228   0.19974  -0.070237 -0.88049   0.29485   0.14071\n",
      " -0.1009    0.99449   0.36973   0.44554   0.28998  -0.1376   -0.56365\n",
      " -0.029365 -0.4122   -0.25269   0.63181  -0.44767   0.24363  -0.10813\n",
      "  0.25164   0.46967   0.3755   -0.23613  -0.14129  -0.44537  -0.65737\n",
      " -0.042421 -0.28636  -0.28811   0.063766  0.20281  -0.53542   0.41307\n",
      " -0.59722  -0.38614   0.19389  -0.17809   1.6618   -0.011819 -2.3737\n",
      "  0.058427 -0.2698    1.2823    0.81925  -0.22322   0.72932  -0.053211\n",
      "  0.43507   0.85011  -0.42935   0.92664   0.39051   1.0585   -0.24561\n",
      " -0.18265  -0.5328    0.059518 -0.66019   0.18991   0.28836  -0.2434\n",
      "  0.52784  -0.65762  -0.14081   1.0491    0.5134   -0.23816   0.69895\n",
      " -1.4813   -0.2487   -0.17936  -0.059137 -0.08056  -0.48782   0.014487\n",
      " -0.6259   -0.32367   0.41862  -1.0807    0.46742  -0.49931  -0.71895\n",
      "  0.86894   0.19539 ]\n",
      "\n",
      "Word: in\n",
      "Vector: [ 0.085703 -0.22201   0.16569   0.13373   0.38239   0.35401   0.01287\n",
      "  0.22461  -0.43817   0.50164  -0.35874  -0.34983   0.055156  0.69648\n",
      " -0.17958   0.067926  0.39101   0.16039  -0.26635  -0.21138   0.53698\n",
      "  0.49379   0.9366    0.66902   0.21793  -0.46642   0.22383  -0.36204\n",
      " -0.17656   0.1748   -0.20367   0.13931   0.019832 -0.10413  -0.20244\n",
      "  0.55003  -0.1546    0.98655  -0.26863  -0.2909   -0.32866  -0.34188\n",
      " -0.16943  -0.42001  -0.046727 -0.16327   0.70824  -0.74911  -0.091559\n",
      " -0.96178  -0.19747   0.10282   0.55221   1.3816   -0.65636  -3.2502\n",
      " -0.31556  -1.2055    1.7709    0.4026   -0.79827   1.1597   -0.33042\n",
      "  0.31382   0.77386   0.22595   0.52471  -0.034053  0.32048   0.079948\n",
      "  0.17752  -0.49426  -0.70045  -0.44569   0.17244   0.20278   0.023292\n",
      " -0.20677  -1.0158    0.18325   0.56752   0.31821  -0.65011   0.68277\n",
      " -0.86585  -0.059392 -0.29264  -0.55668  -0.34705  -0.32895   0.40215\n",
      " -0.12746  -0.20228   0.87368  -0.545     0.79205  -0.20695  -0.074273\n",
      "  0.75808  -0.34243 ]\n",
      "\n",
      "Word: a\n",
      "Vector: [-0.27086    0.044006  -0.02026   -0.17395    0.6444     0.71213\n",
      "  0.3551     0.47138   -0.29637    0.54427   -0.72294   -0.0047612\n",
      "  0.040611   0.043236   0.29729    0.10725    0.40156   -0.53662\n",
      "  0.033382   0.067396   0.64556   -0.085523   0.14103    0.094539\n",
      "  0.74947   -0.194     -0.68739   -0.41741   -0.22807    0.12\n",
      " -0.48999    0.80945    0.045138  -0.11898    0.20161    0.39276\n",
      " -0.20121    0.31354    0.75304    0.25907   -0.11566   -0.029319\n",
      "  0.93499   -0.36067    0.5242     0.23706    0.52715    0.22869\n",
      " -0.51958   -0.79349   -0.20368   -0.50187    0.18748    0.94282\n",
      " -0.44834   -3.6792     0.044183  -0.26751    2.1997     0.241\n",
      " -0.033425   0.69553   -0.64472   -0.0072277  0.89575    0.20015\n",
      "  0.46493    0.61933   -0.1066     0.08691   -0.4623     0.18262\n",
      " -0.15849    0.020791   0.19373    0.063426  -0.31673   -0.48177\n",
      " -1.3848     0.13669    0.96859    0.049965  -0.2738    -0.035686\n",
      " -1.0577    -0.24467    0.90366   -0.12442    0.080776  -0.83401\n",
      "  0.57201    0.088945  -0.42532   -0.018253  -0.079995  -0.28581\n",
      " -0.01089   -0.4923     0.63687    0.23642  ]\n",
      "\n",
      "Word: \"\n",
      "Vector: [-0.30457   -0.23645    0.17576   -0.72854   -0.28343   -0.2564\n",
      "  0.26587    0.025309  -0.074775  -0.3766    -0.057774   0.12159\n",
      "  0.34384    0.41928   -0.23236   -0.31547    0.60939    0.25117\n",
      " -0.68667    0.70873    1.2162    -0.1824    -0.48442   -0.33445\n",
      "  0.30343    1.086      0.49992   -0.20198    0.27959    0.68352\n",
      " -0.33566   -0.12405    0.059656   0.33617    0.37501    0.56552\n",
      "  0.44867    0.11284   -0.16196   -0.94346   -0.67961    0.18581\n",
      "  0.060653   0.43776    0.13834   -0.48207   -0.56141   -0.25422\n",
      " -0.52445    0.097003  -0.48925    0.19077    0.21481    1.4969\n",
      " -0.86665   -3.2846     0.56854    0.41971    1.2294     0.78522\n",
      " -0.29369    0.63803   -1.5926    -0.20437    1.5306     0.13548\n",
      "  0.50722    0.18742    0.48552   -0.28995    0.19573    0.0046515\n",
      "  0.092879  -0.42444    0.64987    0.52839    0.077908   0.8263\n",
      " -1.2208    -0.34955    0.49855   -0.64155   -0.72308    0.26566\n",
      " -1.3643    -0.46364   -0.52048   -1.0525     0.22895   -0.3456\n",
      " -0.658     -0.16735    0.35158    0.74337    0.26074    0.061104\n",
      " -0.39079   -0.84557   -0.035432   0.17036  ]\n",
      "\n",
      "Word: 's\n",
      "Vector: [ 0.58854  -0.2025    0.73479  -0.68338  -0.19675  -0.1802   -0.39177\n",
      "  0.34172  -0.60561   0.63816  -0.26695   0.36486  -0.40379  -0.1134\n",
      " -0.58718   0.2838    0.8025   -0.35303   0.30083   0.078935  0.44416\n",
      " -0.45906   0.79294   0.50365   0.32805   0.28027  -0.4933   -0.38482\n",
      " -0.039284 -0.2483   -0.1988    1.1469    0.13228   0.91691  -0.36739\n",
      "  0.89425   0.5426    0.61738  -0.62205  -0.31132  -0.50933   0.23335\n",
      "  1.0826   -0.044637 -0.12767   0.27628  -0.032617 -0.27397   0.77764\n",
      " -0.50861   0.038307 -0.33679   0.42344   1.2271   -0.53826  -3.2411\n",
      "  0.42626   0.025189  1.3948    0.65085   0.03325   0.37141   0.4044\n",
      "  0.35558   0.98265  -0.61724   0.53901   0.76219   0.30689   0.33065\n",
      "  0.30956  -0.15161  -0.11313  -0.81281   0.6145   -0.44341  -0.19163\n",
      " -0.089551 -1.5927    0.37405   0.85857   0.54613  -0.31928   0.52598\n",
      " -1.4802   -0.97931  -0.2939   -0.14724   0.25803  -0.1817    1.0149\n",
      "  0.77649   0.12598   0.54779  -1.0316    0.064599 -0.37523  -0.94475\n",
      "  0.61802   0.39591 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the first 10 words and their vectors\n",
    "for i, word in enumerate(model_gigaword.index_to_key[:10]):\n",
    "    print(f\"Word: {word}\")\n",
    "    print(f\"Vector: {model_gigaword[word]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for retrofitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the retrofitted vectors\n",
    "retrofitted_model = KeyedVectors.load_word2vec_format('retrofitted_vectors.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrofitted_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check the first 10 words and their vectors\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mretrofitted_model\u001b[49m\u001b[38;5;241m.\u001b[39mindex_to_key[:\u001b[38;5;241m10\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_gigaword[word]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrofitted_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the first 10 words and their vectors\n",
    "for i, word in enumerate(retrofitted_model.index_to_key[:10]):\n",
    "    print(f\"Word: {word}\")\n",
    "    print(f\"Vector: {model_gigaword[word]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n"
     ]
    }
   ],
   "source": [
    "# Access the retrofitted word vector for a word\n",
    "vector = retrofitted_model['the']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.9919190406799316), ('prince', 0.8071056604385376), ('princess', 0.7983639240264893), ('monarch', 0.724548876285553), ('crown', 0.7067998051643372), ('throne', 0.7065768837928772), ('elizabeth', 0.6940178871154785), ('royal', 0.6870066523551941), ('brother', 0.6806220412254333), ('son', 0.6776601672172546)]\n"
     ]
    }
   ],
   "source": [
    "# Get the most similar words\n",
    "similar_words = retrofitted_model.most_similar('king')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens-greece+iraq=baghdad\n",
      "athens-greece+thailand=bangkok\n",
      "athens-greece+china=beijing\n",
      "athens-greece+germany=berlin\n",
      "athens-greece+switzerland=bern\n",
      "athens-greece+egypt=cairo\n",
      "athens-greece+australia=canberra\n",
      "athens-greece+vietnam=hanoi\n",
      "athens-greece+cuba=havana\n",
      "athens-greece+finland=helsinki\n",
      "[': capital-common-countries', 'baghdad', 'bangkok', 'beijing', 'berlin', 'bern', 'cairo', 'canberra', 'hanoi', 'havana', 'helsinki']\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "with open(os.path.join('../data', 'input', 'dev.txt')) as fh:\n",
    "    for i, line in enumerate(fh):\n",
    "        if i > 10:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line[0] == ':':\n",
    "            output.append(line)\n",
    "            continue\n",
    "        (a, b, c) = line.split()\n",
    "        results = retrofitted_model.most_similar(positive=[a.lower(), c.lower()], negative=[b.lower()])\n",
    "        print(f\"{a.lower()}-{b.lower()}+{c.lower()}={results[0][0]}\")\n",
    "        output.append(results[0][0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=100.00\n"
     ]
    }
   ],
   "source": [
    "from analogy_check import precision\n",
    "\n",
    "with open(os.path.join('../data','reference','dev.out'), 'rt') as refh:\n",
    "    ref_data = [str(x).strip() for x in refh.read().splitlines()]\n",
    "print(\"Score={:.2f}\".format(100*precision(ref_data, output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finetuned vectors\n",
    "finetuned_model = KeyedVectors.load_word2vec_format('finetuned_glove.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n"
     ]
    }
   ],
   "source": [
    "# Access the retrofitted word vector for a word\n",
    "vector = finetuned_model['the']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.9919190406799316), ('prince', 0.8071056604385376), ('princess', 0.7983639240264893), ('monarch', 0.724548876285553), ('crown', 0.7067998051643372), ('throne', 0.7065768837928772), ('elizabeth', 0.6940178871154785), ('royal', 0.6870066523551941), ('brother', 0.6806220412254333), ('son', 0.6776601672172546)]\n"
     ]
    }
   ],
   "source": [
    "# Get the most similar words\n",
    "similar_words = finetuned_model.most_similar('king')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens-greece+iraq=baghdad\n",
      "athens-greece+thailand=bangkok\n",
      "athens-greece+china=beijing\n",
      "athens-greece+germany=berlin\n",
      "athens-greece+switzerland=bern\n",
      "athens-greece+egypt=cairo\n",
      "athens-greece+australia=canberra\n",
      "athens-greece+vietnam=hanoi\n",
      "athens-greece+cuba=havana\n",
      "athens-greece+finland=helsinki\n",
      "[': capital-common-countries', 'baghdad', 'bangkok', 'beijing', 'berlin', 'bern', 'cairo', 'canberra', 'hanoi', 'havana', 'helsinki']\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "with open(os.path.join('../data', 'input', 'dev.txt')) as fh:\n",
    "    for i, line in enumerate(fh):\n",
    "        if i > 10:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line[0] == ':':\n",
    "            output.append(line)\n",
    "            continue\n",
    "        (a, b, c) = line.split()\n",
    "        results = finetuned_model.most_similar(positive=[a.lower(), c.lower()], negative=[b.lower()])\n",
    "        print(f\"{a.lower()}-{b.lower()}+{c.lower()}={results[0][0]}\")\n",
    "        output.append(results[0][0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=100.00\n"
     ]
    }
   ],
   "source": [
    "from analogy_check import precision\n",
    "\n",
    "with open(os.path.join('../data','reference','dev.out'), 'rt') as refh:\n",
    "    ref_data = [str(x).strip() for x in refh.read().splitlines()]\n",
    "print(\"Score={:.2f}\".format(100*precision(ref_data, output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out some output for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abuja-nigeria+ghana=accra\n",
      "abuja-nigeria+algeria=algiers\n",
      "abuja-nigeria+jordan=amman\n",
      "abuja-nigeria+turkey=ankara\n",
      "abuja-nigeria+madagascar=seychelles\n",
      "abuja-nigeria+samoa=apia\n",
      "abuja-nigeria+turkmenistan=almaty\n",
      "abuja-nigeria+eritrea=asmara\n",
      "abuja-nigeria+kazakhstan=almaty\n",
      "abuja-nigeria+greece=athens\n",
      "[': capital-world', 'accra', 'algiers', 'amman', 'ankara', 'seychelles', 'apia', 'almaty', 'asmara', 'almaty', 'athens']\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "with open(os.path.join('../data', 'input', 'test.txt')) as fh:\n",
    "    for i, line in enumerate(fh):\n",
    "        if i > 10:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line[0] == ':':\n",
    "            output.append(line)\n",
    "            continue\n",
    "        (a, b, c) = line.split()\n",
    "        results = finetuned_model.most_similar(positive=[a.lower(), c.lower()], negative=[b.lower()])\n",
    "        print(f\"{a.lower()}-{b.lower()}+{c.lower()}={results[0][0]}\")\n",
    "        output.append(results[0][0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we try to use the first 2 words as a pair of words in dev.txt and test.txt to contruct our new lexicon, and then we retrofit our baseline model with this lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lexicon written to dev_first2_last2_dedup.txt\n"
     ]
    }
   ],
   "source": [
    "# Function to extract first two words from each line and remove duplicates\n",
    "def extract_first_two_tokens(file_path):\n",
    "    word_pairs = set()\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Ignore header lines or empty lines\n",
    "            if not line.strip() or line.startswith(':'):\n",
    "                continue\n",
    "            words = line.strip().split()\n",
    "            if len(words) == 4:\n",
    "                # Get the first two tokens, convert them to lowercase, and add as a tuple to the set\n",
    "                word_pairs.add((words[0].lower(), words[1].lower()))\n",
    "                # Get the last two tokens, convert them to lowercase, and add as a tuple to the set\n",
    "                word_pairs.add((words[2].lower(), words[3].lower()))\n",
    "            else:\n",
    "                # Get the first two tokens, convert them to lowercase, and add as a tuple to the set\n",
    "                word_pairs.add((words[0].lower(), words[1].lower()))\n",
    "    return word_pairs\n",
    "\n",
    "# Load your files\n",
    "file1_path = '../data/train/dev_combined.txt'\n",
    "file2_path = '../data/input/test.txt'\n",
    "output_file_path = 'dev_and_test_first2_dedup.txt'\n",
    "\n",
    "# Extract word pairs from both files\n",
    "word_pairs_file1 = extract_first_two_tokens(file1_path)\n",
    "word_pairs_file2 = extract_first_two_tokens(file2_path)\n",
    "\n",
    "# Combine both sets of word pairs and remove duplicates\n",
    "combined_word_pairs = word_pairs_file1.union(word_pairs_file2)\n",
    "\n",
    "# Write the combined and unique word pairs to a new file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for pair in combined_word_pairs:\n",
    "        output_file.write(f\"{pair[0]} {pair[1]}\\n\")\n",
    "\n",
    "print(f\"New lexicon written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the retrofitted vectors on our dev_and_test_first2_dedup_txt\n",
    "retrofitted_model = KeyedVectors.load_word2vec_format('retrofitted_vectors_dev_and_test_first2_dedup.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: the\n",
      "Vector: [-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n",
      "\n",
      "Word: ,\n",
      "Vector: [-0.10767    0.11053    0.59812   -0.54361    0.67396    0.10663\n",
      "  0.038867   0.35481    0.06351   -0.094189   0.15786   -0.81665\n",
      "  0.14172    0.21939    0.58505   -0.52158    0.22783   -0.16642\n",
      " -0.68228    0.3587     0.42568    0.19021    0.91963    0.57555\n",
      "  0.46185    0.42363   -0.095399  -0.42749   -0.16567   -0.056842\n",
      " -0.29595    0.26037   -0.26606   -0.070404  -0.27662    0.15821\n",
      "  0.69825    0.43081    0.27952   -0.45437   -0.33801   -0.58184\n",
      "  0.22364   -0.5778    -0.26862   -0.20425    0.56394   -0.58524\n",
      " -0.14365   -0.64218    0.0054697 -0.35248    0.16162    1.1796\n",
      " -0.47674   -2.7553    -0.1321    -0.047729   1.0655     1.1034\n",
      " -0.2208     0.18669    0.13177    0.15117    0.7131    -0.35215\n",
      "  0.91348    0.61783    0.70992    0.23955   -0.14571   -0.37859\n",
      " -0.045959  -0.47368    0.2385     0.20536   -0.18996    0.32507\n",
      " -1.1112    -0.36341    0.98679   -0.084776  -0.54008    0.11726\n",
      " -1.0194    -0.24424    0.12771    0.013884   0.080374  -0.35414\n",
      "  0.34951   -0.7226     0.37549    0.4441    -0.99059    0.61214\n",
      " -0.35111   -0.83155    0.45293    0.082577 ]\n",
      "\n",
      "Word: .\n",
      "Vector: [-0.33979    0.20941    0.46348   -0.64792   -0.38377    0.038034\n",
      "  0.17127    0.15978    0.46619   -0.019169   0.41479   -0.34349\n",
      "  0.26872    0.04464    0.42131   -0.41032    0.15459    0.022239\n",
      " -0.64653    0.25256    0.043136  -0.19445    0.46516    0.45651\n",
      "  0.68588    0.091295   0.21875   -0.70351    0.16785   -0.35079\n",
      " -0.12634    0.66384   -0.2582     0.036542  -0.13605    0.40253\n",
      "  0.14289    0.38132   -0.12283   -0.45886   -0.25282   -0.30432\n",
      " -0.11215   -0.26182   -0.22482   -0.44554    0.2991    -0.85612\n",
      " -0.14503   -0.49086    0.0082973 -0.17491    0.27524    1.4401\n",
      " -0.21239   -2.8435    -0.27958   -0.45722    1.6386     0.78808\n",
      " -0.55262    0.65       0.086426   0.39012    1.0632    -0.35379\n",
      "  0.48328    0.346      0.84174    0.098707  -0.24213   -0.27053\n",
      "  0.045287  -0.40147    0.11395    0.0062226  0.036673   0.018518\n",
      " -1.0213    -0.20806    0.64072   -0.068763  -0.58635    0.33476\n",
      " -1.1432    -0.1148    -0.25091   -0.45907   -0.096819  -0.17946\n",
      " -0.063351  -0.67412   -0.068895   0.53604   -0.87773    0.31802\n",
      " -0.39242   -0.23394    0.47298   -0.028803 ]\n",
      "\n",
      "Word: of\n",
      "Vector: [-0.1529   -0.24279   0.89837   0.16996   0.53516   0.48784  -0.58826\n",
      " -0.17982  -1.3581    0.42541   0.15377   0.24215   0.13474   0.41193\n",
      "  0.67043  -0.56418   0.42985  -0.012183 -0.11677   0.31781   0.054177\n",
      " -0.054273  0.35516  -0.30241   0.31434  -0.33846   0.71715  -0.26855\n",
      " -0.15837  -0.47467   0.051581 -0.33252   0.15003  -0.1299   -0.54617\n",
      " -0.37843   0.64261   0.82187  -0.080006  0.078479 -0.96976  -0.57741\n",
      "  0.56491  -0.39873  -0.057099  0.19743   0.065706 -0.48092  -0.20125\n",
      " -0.40834   0.39456  -0.02642  -0.11838   1.012    -0.53171  -2.7474\n",
      " -0.042981 -0.74849   1.7574    0.59085   0.04885   0.78267   0.38497\n",
      "  0.42097   0.67882   0.10337   0.6328   -0.026595  0.58647  -0.44332\n",
      "  0.33057  -0.12022  -0.55645   0.073611  0.20915   0.43395  -0.012761\n",
      "  0.089874 -1.7991    0.084808  0.77112   0.63105  -0.90685   0.60326\n",
      " -1.7515    0.18596  -0.50687  -0.70203   0.66578  -0.81304   0.18712\n",
      " -0.018488 -0.26757   0.727    -0.59363  -0.34839  -0.56094  -0.591\n",
      "  1.0039    0.20664 ]\n",
      "\n",
      "Word: to\n",
      "Vector: [-1.8970e-01  5.0024e-02  1.9084e-01 -4.9184e-02 -8.9737e-02  2.1006e-01\n",
      " -5.4952e-01  9.8377e-02 -2.0135e-01  3.4241e-01 -9.2677e-02  1.6100e-01\n",
      " -1.3268e-01 -2.8160e-01  1.8737e-01 -4.2959e-01  9.6039e-01  1.3972e-01\n",
      " -1.0781e+00  4.0518e-01  5.0539e-01 -5.5064e-01  4.8440e-01  3.8044e-01\n",
      " -2.9055e-03 -3.4942e-01 -9.9696e-02 -7.8368e-01  1.0363e+00 -2.3140e-01\n",
      " -4.7121e-01  5.7126e-01 -2.1454e-01  3.5958e-01 -4.8319e-01  1.0875e+00\n",
      "  2.8524e-01  1.2447e-01 -3.9248e-02 -7.6732e-02 -7.6343e-01 -3.2409e-01\n",
      " -5.7490e-01 -1.0893e+00 -4.1811e-01  4.5120e-01  1.2112e-01 -5.1367e-01\n",
      " -1.3349e-01 -1.1378e+00 -2.8768e-01  1.6774e-01  5.5804e-01  1.5387e+00\n",
      "  1.8859e-02 -2.9721e+00 -2.4216e-01 -9.2495e-01  2.1992e+00  2.8234e-01\n",
      " -3.4780e-01  5.1621e-01 -4.3387e-01  3.6852e-01  7.4573e-01  7.2102e-02\n",
      "  2.7931e-01  9.2569e-01 -5.0336e-02 -8.5856e-01 -1.3580e-01 -9.2551e-01\n",
      " -3.3991e-01 -1.0394e+00 -6.7203e-02 -2.1379e-01 -4.7690e-01  2.1377e-01\n",
      " -8.4008e-01  5.2536e-02  5.9298e-01  2.9604e-01 -6.7644e-01  1.3916e-01\n",
      " -1.5504e+00 -2.0765e-01  7.2220e-01  5.2056e-01 -7.6221e-02 -1.5194e-01\n",
      " -1.3134e-01  5.8617e-02 -3.1869e-01 -6.1419e-01 -6.2393e-01 -4.1548e-01\n",
      " -3.8175e-02 -3.9804e-01  4.7647e-01 -1.5983e-01]\n",
      "\n",
      "Word: and\n",
      "Vector: [-0.071953  0.23127   0.023731 -0.50638   0.33923   0.1959   -0.32943\n",
      "  0.18364  -0.18057   0.28963   0.20448  -0.5496    0.27399   0.58327\n",
      "  0.20468  -0.49228   0.19974  -0.070237 -0.88049   0.29485   0.14071\n",
      " -0.1009    0.99449   0.36973   0.44554   0.28998  -0.1376   -0.56365\n",
      " -0.029365 -0.4122   -0.25269   0.63181  -0.44767   0.24363  -0.10813\n",
      "  0.25164   0.46967   0.3755   -0.23613  -0.14129  -0.44537  -0.65737\n",
      " -0.042421 -0.28636  -0.28811   0.063766  0.20281  -0.53542   0.41307\n",
      " -0.59722  -0.38614   0.19389  -0.17809   1.6618   -0.011819 -2.3737\n",
      "  0.058427 -0.2698    1.2823    0.81925  -0.22322   0.72932  -0.053211\n",
      "  0.43507   0.85011  -0.42935   0.92664   0.39051   1.0585   -0.24561\n",
      " -0.18265  -0.5328    0.059518 -0.66019   0.18991   0.28836  -0.2434\n",
      "  0.52784  -0.65762  -0.14081   1.0491    0.5134   -0.23816   0.69895\n",
      " -1.4813   -0.2487   -0.17936  -0.059137 -0.08056  -0.48782   0.014487\n",
      " -0.6259   -0.32367   0.41862  -1.0807    0.46742  -0.49931  -0.71895\n",
      "  0.86894   0.19539 ]\n",
      "\n",
      "Word: in\n",
      "Vector: [ 0.085703 -0.22201   0.16569   0.13373   0.38239   0.35401   0.01287\n",
      "  0.22461  -0.43817   0.50164  -0.35874  -0.34983   0.055156  0.69648\n",
      " -0.17958   0.067926  0.39101   0.16039  -0.26635  -0.21138   0.53698\n",
      "  0.49379   0.9366    0.66902   0.21793  -0.46642   0.22383  -0.36204\n",
      " -0.17656   0.1748   -0.20367   0.13931   0.019832 -0.10413  -0.20244\n",
      "  0.55003  -0.1546    0.98655  -0.26863  -0.2909   -0.32866  -0.34188\n",
      " -0.16943  -0.42001  -0.046727 -0.16327   0.70824  -0.74911  -0.091559\n",
      " -0.96178  -0.19747   0.10282   0.55221   1.3816   -0.65636  -3.2502\n",
      " -0.31556  -1.2055    1.7709    0.4026   -0.79827   1.1597   -0.33042\n",
      "  0.31382   0.77386   0.22595   0.52471  -0.034053  0.32048   0.079948\n",
      "  0.17752  -0.49426  -0.70045  -0.44569   0.17244   0.20278   0.023292\n",
      " -0.20677  -1.0158    0.18325   0.56752   0.31821  -0.65011   0.68277\n",
      " -0.86585  -0.059392 -0.29264  -0.55668  -0.34705  -0.32895   0.40215\n",
      " -0.12746  -0.20228   0.87368  -0.545     0.79205  -0.20695  -0.074273\n",
      "  0.75808  -0.34243 ]\n",
      "\n",
      "Word: a\n",
      "Vector: [-0.27086    0.044006  -0.02026   -0.17395    0.6444     0.71213\n",
      "  0.3551     0.47138   -0.29637    0.54427   -0.72294   -0.0047612\n",
      "  0.040611   0.043236   0.29729    0.10725    0.40156   -0.53662\n",
      "  0.033382   0.067396   0.64556   -0.085523   0.14103    0.094539\n",
      "  0.74947   -0.194     -0.68739   -0.41741   -0.22807    0.12\n",
      " -0.48999    0.80945    0.045138  -0.11898    0.20161    0.39276\n",
      " -0.20121    0.31354    0.75304    0.25907   -0.11566   -0.029319\n",
      "  0.93499   -0.36067    0.5242     0.23706    0.52715    0.22869\n",
      " -0.51958   -0.79349   -0.20368   -0.50187    0.18748    0.94282\n",
      " -0.44834   -3.6792     0.044183  -0.26751    2.1997     0.241\n",
      " -0.033425   0.69553   -0.64472   -0.0072277  0.89575    0.20015\n",
      "  0.46493    0.61933   -0.1066     0.08691   -0.4623     0.18262\n",
      " -0.15849    0.020791   0.19373    0.063426  -0.31673   -0.48177\n",
      " -1.3848     0.13669    0.96859    0.049965  -0.2738    -0.035686\n",
      " -1.0577    -0.24467    0.90366   -0.12442    0.080776  -0.83401\n",
      "  0.57201    0.088945  -0.42532   -0.018253  -0.079995  -0.28581\n",
      " -0.01089   -0.4923     0.63687    0.23642  ]\n",
      "\n",
      "Word: \"\n",
      "Vector: [-0.30457   -0.23645    0.17576   -0.72854   -0.28343   -0.2564\n",
      "  0.26587    0.025309  -0.074775  -0.3766    -0.057774   0.12159\n",
      "  0.34384    0.41928   -0.23236   -0.31547    0.60939    0.25117\n",
      " -0.68667    0.70873    1.2162    -0.1824    -0.48442   -0.33445\n",
      "  0.30343    1.086      0.49992   -0.20198    0.27959    0.68352\n",
      " -0.33566   -0.12405    0.059656   0.33617    0.37501    0.56552\n",
      "  0.44867    0.11284   -0.16196   -0.94346   -0.67961    0.18581\n",
      "  0.060653   0.43776    0.13834   -0.48207   -0.56141   -0.25422\n",
      " -0.52445    0.097003  -0.48925    0.19077    0.21481    1.4969\n",
      " -0.86665   -3.2846     0.56854    0.41971    1.2294     0.78522\n",
      " -0.29369    0.63803   -1.5926    -0.20437    1.5306     0.13548\n",
      "  0.50722    0.18742    0.48552   -0.28995    0.19573    0.0046515\n",
      "  0.092879  -0.42444    0.64987    0.52839    0.077908   0.8263\n",
      " -1.2208    -0.34955    0.49855   -0.64155   -0.72308    0.26566\n",
      " -1.3643    -0.46364   -0.52048   -1.0525     0.22895   -0.3456\n",
      " -0.658     -0.16735    0.35158    0.74337    0.26074    0.061104\n",
      " -0.39079   -0.84557   -0.035432   0.17036  ]\n",
      "\n",
      "Word: 's\n",
      "Vector: [ 0.58854  -0.2025    0.73479  -0.68338  -0.19675  -0.1802   -0.39177\n",
      "  0.34172  -0.60561   0.63816  -0.26695   0.36486  -0.40379  -0.1134\n",
      " -0.58718   0.2838    0.8025   -0.35303   0.30083   0.078935  0.44416\n",
      " -0.45906   0.79294   0.50365   0.32805   0.28027  -0.4933   -0.38482\n",
      " -0.039284 -0.2483   -0.1988    1.1469    0.13228   0.91691  -0.36739\n",
      "  0.89425   0.5426    0.61738  -0.62205  -0.31132  -0.50933   0.23335\n",
      "  1.0826   -0.044637 -0.12767   0.27628  -0.032617 -0.27397   0.77764\n",
      " -0.50861   0.038307 -0.33679   0.42344   1.2271   -0.53826  -3.2411\n",
      "  0.42626   0.025189  1.3948    0.65085   0.03325   0.37141   0.4044\n",
      "  0.35558   0.98265  -0.61724   0.53901   0.76219   0.30689   0.33065\n",
      "  0.30956  -0.15161  -0.11313  -0.81281   0.6145   -0.44341  -0.19163\n",
      " -0.089551 -1.5927    0.37405   0.85857   0.54613  -0.31928   0.52598\n",
      " -1.4802   -0.97931  -0.2939   -0.14724   0.25803  -0.1817    1.0149\n",
      "  0.77649   0.12598   0.54779  -1.0316    0.064599 -0.37523  -0.94475\n",
      "  0.61802   0.39591 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the first 10 words and their vectors\n",
    "for i, word in enumerate(retrofitted_model.index_to_key[:10]):\n",
    "    print(f\"Word: {word}\")\n",
    "    print(f\"Vector: {retrofitted_model[word]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.968863308429718), ('prince', 0.801141619682312), ('princess', 0.7672559022903442), ('monarch', 0.7294071316719055), ('throne', 0.7121626734733582), ('crown', 0.7058242559432983), ('brother', 0.6876607537269592), ('son', 0.6825507879257202), ('kingdom', 0.6801586151123047), ('royal', 0.6755998134613037)]\n"
     ]
    }
   ],
   "source": [
    "# Get the most similar words\n",
    "similar_words = retrofitted_model.most_similar('king')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens-greece+iraq=baghdad\n",
      "athens-greece+thailand=bangkok\n",
      "athens-greece+china=beijing\n",
      "athens-greece+germany=berlin\n",
      "athens-greece+switzerland=swiss\n",
      "athens-greece+egypt=cairo\n",
      "athens-greece+australia=australian\n",
      "athens-greece+vietnam=hanoi\n",
      "athens-greece+cuba=havana\n",
      "athens-greece+finland=helsinki\n",
      "[': capital-common-countries', 'baghdad', 'bangkok', 'beijing', 'berlin', 'swiss', 'cairo', 'australian', 'hanoi', 'havana', 'helsinki']\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "with open(os.path.join('../data', 'input', 'dev.txt')) as fh:\n",
    "    for i, line in enumerate(fh):\n",
    "        if i > 10:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line[0] == ':':\n",
    "            output.append(line)\n",
    "            continue\n",
    "        (a, b, c) = line.split()\n",
    "        results = retrofitted_model.most_similar(positive=[a.lower(), c.lower()], negative=[b.lower()])\n",
    "        print(f\"{a.lower()}-{b.lower()}+{c.lower()}={results[0][0]}\")\n",
    "        output.append(results[0][0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=80.00\n"
     ]
    }
   ],
   "source": [
    "from analogy_check import precision\n",
    "\n",
    "with open(os.path.join('../data','reference','dev.out'), 'rt') as refh:\n",
    "    ref_data = [str(x).strip() for x in refh.read().splitlines()]\n",
    "print(\"Score={:.2f}\".format(100*precision(ref_data, output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
