{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-mNy2No3g2ZS"},"outputs":[],"source":["!pip install transformers torch datasets tqdm sacrebleu trl peft bitsandbytes fuzzywuzzy"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":570,"status":"ok","timestamp":1732229201549,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"LXVx4y5lg2XG","outputId":"466ad063-1448-4d99-d65c-bc7d15cd51d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","drive  sample_data\n","Thu Nov 21 22:46:41 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n","| N/A   71C    P0              35W /  72W |      1MiB / 23034MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!pwd # shows current directory\n","!ls  # shows all files in this directory\n","!nvidia-smi # shows the specs and the current status of the allocated GPU"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1034,"status":"ok","timestamp":1732229202582,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"RFoy2mI-h_t5","outputId":"0e80e0ec-3b45-4673-a264-d6afbcdc830a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1732229202582,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"AooeJ4qyiYaA","outputId":"c6bb768d-fdbf-44a0-d0e5-12dbcbe048d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/frefopt/answer\n"]}],"source":["%cd /content/drive/MyDrive/frefopt/answer/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jid7nzbLh2mP","executionInfo":{"status":"ok","timestamp":1732229211718,"user_tz":480,"elapsed":8408,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"a8a840bc-c338-40b0-b9f1-33ac6104ea84"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]}],"source":["from default import *\n","from pathlib import Path\n","import os, sys\n","import torch\n","import json\n","import gzip\n","import wandb\n","from tqdm import tqdm\n","import random\n","from fuzzywuzzy import fuzz\n","from fuzzywuzzy import process\n","import re\n","from collections import defaultdict\n","import logging\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from datasets import Dataset\n","import argparse\n","from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, BitsAndBytesConfig, TrainingArguments, pipeline\n","from trl import ORPOTrainer, ORPOConfig, ScriptArguments, ModelConfig, get_peft_config, setup_chat_format\n","from peft import PeftModel, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from datasets import load_dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo7b6tgBg2Qa","executionInfo":{"status":"ok","timestamp":1732229211718,"user_tz":480,"elapsed":2,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"c435bf70-9dbc-44d8-ca0c-c074d3c76bbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"source":["# Make sure that GPU is available for your notebook.\n","# Otherwise, you need to update the settungs in Runtime -> Change runtime type -> Hardware accelerator\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"MsVADoRigxQV"},"source":["# prefopt: default program"]},{"cell_type":"markdown","metadata":{"id":"l-BFbzw6gxQb"},"source":["## Run the default solution on small"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EUmEV0YgxQc"},"outputs":[],"source":["basemodel = 'Qwen/Qwen2.5-0.5B-Instruct'\n","device = 'cuda'\n","inputfile = os.path.join('..','data', 'input', 'dev.txt')\n","logging.basicConfig(filename='log.txt', filemode='w', level=logging.DEBUG)"]},{"cell_type":"markdown","metadata":{"id":"p5MpWmKkgxQc"},"source":["Decode the inputfile. **Warning**: This will take some time to run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4LkgcQ2gxQd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732146938266,"user_tz":480,"elapsed":94199,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"6bc07e09-6bb8-4b36-8e10-a20de0cc6356"},"outputs":[{"output_type":"stream","name":"stderr","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"]}],"source":["%%capture output\n","decode_all(basemodel, device, inputfile)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVDzLQhVgxQk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732146938266,"user_tz":480,"elapsed":6,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"d6755182-b733-4984-d6d3-63478a577d14"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\"output\": \"-2\"}\n","{\"output\": \"am\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Based on the provided ingredient lists and their corresponding dishes, I would classify them as follows:\\n\\n1. Pepperoni - This could potentially fit in either the Pizza or Sandwich category depending on how it's prepared. However, since it doesn't specify a type of pizza or sandwich, we can't definitively say it belongs to one class.\\n\\n2. Tomato sauce - This typically goes with a sandwich, not a pizza. It's more commonly used in sandwiches than pizzas.\\n\\n3. Cheese - This is a staple in both sandwiches and pizzas, so it fits well in both categories.\\n\\n4. Bread dough - This is often used in both sandwiches and\"}\n","{\"output\": \"False\"}\n","{\"output\": \"True\"}\n","{\"output\": \"True\"}\n","{\"output\": \"Based on the content of the review, which highlights positive aspects like timely service and enjoyment of the food while also expressing a desire for more vegan options, the overall sentiment leans towards **POSITIVE**. The reviewer seems satisfied with both their experience and the quality of the food, despite mentioning a potential limitation in offering more vegan options.\"}\n","{\"output\": \"Incident\"}\n","{\"output\": \"To determine if three rectangles with given side lengths can form a triangle, we need to check if the sum of any two sides is greater than the third side. If this condition holds for all combinations of pairs of sides, then the rectangles can form a triangle.\\n\\nFor the given rectangle sides {2, 3, 4}, let's evaluate each combination:\\n\\n1. \\\\(2 + 3 > 4\\\\) (False)\\n2. \\\\(2 + 4 > 3\\\\) (True)\\n3. \\\\(3 + 4 > 2\\\\) (True)\\n\\nSince only the first pair satisfies the triangle inequality theorem, the rectangles cannot\"}\n","{\"output\": \"C\"}\n","{\"output\": \"Based on the content of the review:\\n\\n1. \\\"This restaurant is amazing!\\\": This is clearly positive.\\n2. \\\"The food was great\\\": This is also positive.\\n3. \\\"the service was wonderful\\\": This is also positive.\\n\\nOverall, all three sentences express strong positive sentiments towards the restaurant. Therefore, the overall sentiment of the review can be labeled as:\\n\\n**POSITIVE**\"}\n","{\"output\": \"Here is the array sorted in non-decreasing order: \\n1, 2, 3, 4.\"}\n","{\"output\": \"Not_argumentative\"}\n","{\"output\": \"No, the target string 'abba' cannot be constructed by concatenating some (or all) of the strings from the list ['a', 'bb', 'aaab', 'aba']. The only way to get 'abba' would be if we concatenate each string in the list one after another:\\n\\n- First: 'a'\\n- Second: 'bb'\\n- Third: 'aaab'\\n- Fourth: 'aba'\\n\\nThis results in the string 'abba'.\"}\n","{\"output\": \"No\"}\n","{\"output\": \"To determine if the given list follows an arithmetic progression, we need to check if the difference between consecutive terms is constant.\\n\\nFor the sequence [2, 6, 10, 14], let's calculate the differences:\\n\\n- Difference between 6 and 2: \\\\(6 - 2 = 4\\\\)\\n- Difference between 10 and 6: \\\\(10 - 6 = 4\\\\)\\n- Difference between 14 and 10: \\\\(14 - 10 = 4\\\\)\\n\\nSince all three differences (4) are equal, the sequence does indeed follow an arithmetic progression\"}\n","{\"output\": \"Correct\"}\n","{\"output\": \"N\"}\n","{\"output\": \"No\"}\n","{\"output\": \"0\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"The string \\\"abcdefghijkl\\\" is not a substring of the string \\\"mnopqrstuvwxyz\\\".\"}\n","{\"output\": \"True\"}\n","{\"output\": \"No\"}\n","{\"output\": \"Silence.\"}\n","{\"output\": \"The word at position 7 in the list \\\"cat, sky, blue, book, happy\\\" is \\\"blue\\\". Therefore, the output is 'adjective'.\"}\n","{\"output\": \"factual\"}\n","{\"output\": \"To determine if the array [1, 2, 4] is non-decreasing, we need to check if each element is greater than or equal to the previous one:\\n\\n- 1 <= 2 (True)\\n- 2 <= 4 (True)\\n\\nSince both conditions are true, the answer is 'true'.\"}\n","{\"output\": \"No\"}\n","{\"output\": \"To determine if the pair of sentences \\\"The leaves are falling. :)\\\" and \\\"It's autumn.\\\" form a sequential order, we need to analyze their content and context:\\n\\n1. The first sentence describes a natural phenomenon (leaves falling).\\n2. The second sentence indicates it's currently fall season.\\n\\nThese two statements do not logically follow each other as they describe different events happening at different times of the year. Therefore, they do not form a sequential order.\\n\\nOutput: False\"}\n","{\"output\": \"True\"}\n","{\"output\": \"To solve this problem, we'll split the text into words, convert them to lowercase, and then check each word against the provided word. Here's a Python function to achieve this:\\n\\n```python\\ndef count_word_occurrences(text, word):\\n    # Split the text into words\\n    words = text.split()\\n    \\n    # Convert all words to lowercase\\n    lowercased_words = [word.lower() for word in words]\\n    \\n    # Count occurrences of the word\\n    occurrence_count = sum(word.lower() == word for word in lowercased_words)\\n    \\n    return occurrence_count\\n\\n# Example usage:\\ntext = \\\"One could be\"}\n","{\"output\": \"First\"}\n","{\"output\": \"1\"}\n","{\"output\": \"NEGATIVE\"}\n","{\"output\": \"No\"}\n","{\"output\": \"The output should be 'A'.\\nThis option creates a coherent and well-written story by starting with \\\"As soon as I saw it, I wanted it.\\\" The other options do not fit as well because they either don't connect directly with the initial desire (\\\"It was love at first sight\\\" is too specific), focus on the object itself (\\\"I knew I had to have it\\\"), or imply a future action (\\\"I lusted after it like no tomorrow\\\") which doesn't align with the immediate desire described in the first sentence.\"}\n","{\"output\": \"No\"}\n","{\"output\": \"1 (True)\\n\\nThe definition \\\"of or relating to sound waves that are transmitted through the air\\\" accurately describes what acoustic means. Sound waves travel through the air, which aligns with the concept of being \\\"transmitted through the air.\\\" Therefore, the definition is correct.\"}\n","{\"output\": \"Sad\"}\n","{\"output\": \"0 (False)\"}\n","{\"output\": \"False\"}\n","{\"output\": \"None\"}\n","{\"output\": \"Causal\"}\n","{\"output\": \"The word that fits into all three blanks in the passage is \\\"environment\\\". This completes the sentence:\\n\\n\\\"Designers work on developing products or services while taking into account both form and environment, aesthetics and usability, engineering feasibility, production costs and time limitations as well as user behavior within specific environments.\\\"\\n\\nThis sentence maintains grammatical correctness and contextual relevance.\"}\n","{\"output\": \"Impossible\"}\n","{\"output\": \"Owner\"}\n","{\"output\": \"C\"}\n","{\"output\": \"25431\"}\n","{\"output\": \"No\"}\n","{\"output\": \"No.\"}\n","{\"output\": \"To determine if the first sentence implies the second, I'll analyze them step-by-step:\\n\\n1. The first sentence: \\\"She's been singing all day. :)\\\"\\n   - This suggests she has been actively engaged in singing for some time.\\n\\n2. The second sentence: \\\"She should be tired now.\\\"\\n   - This indicates that she feels tired after singing for a long time.\\n\\nNow, let's consider if these two statements can logically lead to each other:\\n- Singing continuously (as implied by the first sentence) would naturally make someone feel tired.\\n- Feeling tired after singing suggests she may have been working hard and exhausted during her\"}\n","{\"output\": \"FORMAL\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"False\"}\n","{\"output\": \"C\"}\n","{\"output\": \"There is no word in the given passage. The text does not contain any words at all.\"}\n","{\"output\": \"False\"}\n","{\"output\": \"False\"}\n","{\"output\": \"Summary1\"}\n","{\"output\": \"Sure! Please provide the sentences so I can assess their credibility.\"}\n","{\"output\": \"The word \\\"pen\\\" does not occur in the given text. Therefore, the output is:\\n\\n0\"}\n","{\"output\": \"C\"}\n","{\"output\": \"False\"}\n","{\"output\": \"23451\"}\n","{\"output\": \"To determine if the given point ordering is clockwise or counterclockwise, we can analyze the direction of each pair of consecutive points:\\n\\n1. (2, 3) and (5, 7): These points are moving clockwise from left to right.\\n2. (5, 7) and (9, 1): These points are also moving clockwise from left to right.\\n3. (9, 1) and (4, 4): These points are moving counterclockwise from right to left.\\n\\nSince all pairs of consecutive points move in the same direction (either both clockwise or both counterclockwise),\"}\n","{\"output\": \"A\"}\n","{\"output\": \"NEGATIVE\"}\n","{\"output\": \"To find the value of \\\\(X\\\\) in the table, we need to look for a row where the column headers match \\\"X\\\" and then find the corresponding values in columns B and C.\\n\\nFrom the provided table:\\n- The first row has \\\"X\\\" as the header.\\n- In the second row, the values in columns B and C are 4 and 6 respectively.\\n\\nTherefore, the value of \\\\(X\\\\) is 4.\"}\n","{\"output\": \"No\"}\n","{\"output\": \"No.\"}\n","{\"output\": \"23415\"}\n","{\"output\": \"True\"}\n","{\"output\": \"To determine if the second date (12/3/2019) is later than the first date (10/5/2015), you can compare their dates directly.\\n\\nHere's how you can do it:\\n\\n```python\\nfrom datetime import datetime\\n\\n# First date as string: DD MM YYYY\\nfirst_date_str = \\\"10 5 2015\\\"\\nfirst_date = datetime.strptime(first_date_str, \\\"%d %m %Y\\\")\\n\\n# Second date as string: DD MM YYYY\\nsecond_date_str = \\\"12 3 2019\\\"\\nsecond_date = datetime.strptime\"}\n","{\"output\": \"temporal\"}\n","{\"output\": \"Unrelated. The first sentence states that all Americans love baseball, which implies a positive sentiment towards baseball. The second sentence contradicts this by stating that baseball is not popular in America, which is an anti-stereotype.\"}\n","{\"output\": \"1) Put person A on horse B\\n2) Position person A so that their head is level with horse B's head\\n3) Have person C hold onto the end of rope D\\n4) Attach one end of rope D to saddle E\\n5) None\"}\n","{\"output\": \"Positive\"}\n","{\"output\": \"Valid\"}\n","{\"output\": \"Anti-stereotype\"}\n","{\"output\": \"0\"}\n","{\"output\": \"To determine if the given points lie on the same line, we can calculate the slope between any two pairs of points and check if they are equal.\\n\\nGiven points: \\n- (1, 2)\\n- (2, 4)\\n- (3, 6)\\n\\nLet's calculate the slopes:\\n\\n1. Slope between (1, 2) and (2, 4):\\n   \\\\[\\n   m_1 = \\\\frac{y_2 - y_1}{x_2 - x_1} = \\\\frac{4 - 2}{2 - 1} = 2\\n   \\\\]\\n\\n2\"}\n","{\"output\": \"Based on the provided events, the relationship between them is:\\n3) PersonZ divorced - 2) PersonY got married\\nThis indicates that PersonZ (the person who got married) divorced, which logically follows from PersonY getting married.\"}\n","{\"output\": \"neither\"}\n","{\"output\": \"To solve this problem, we can use a hash map to keep track of the elements we've seen so far. As we iterate through the array, we check if the current element has been seen before. If it has, then we have found two elements that are out of order, and we return 'Yes'. Otherwise, we add the current element to our hash map.\\n\\nHere's the Python implementation:\\n\\n```python\\ndef find_swapped_elements(arr):\\n    # Create an empty set to store seen elements\\n    seen = set()\\n    \\n    for num in arr:\\n        # Check if the number is already in the set\\n        if\"}\n","{\"output\": \"No\"}\n","{\"output\": \"Based on the content of the article, it appears that the audience for this piece would most likely be focused on immigrants who have recently moved to the United States or are currently residing there. The article discusses events happening in the United States due to immigration policies and their impact on various communities around the world.\\n\\nGiven this context, I would predict that the audience for this article would fall into category 3 - 'immigrants'. This category includes individuals who are new arrivals to the country, including those who have recently arrived in the United States or are already here but are adjusting to life in the country. The article touches on issues related to immigration,\"}\n","{\"output\": \"\\\"no conflict\\\"\"}\n","{\"output\": \"False. The article does not contain any explicitly negative statements about teachers. While there are some criticisms of teacher workload and pay, these are presented in a balanced manner rather than as outright negative statements. The overall tone seems to lean towards acknowledging challenges faced by teachers while also highlighting efforts being made to improve conditions.\"}\n","{\"output\": \"To determine the domain for each email address provided:\\n\\n1. Contoso: This appears to be a common email address format with a '@' symbol separating the username from the domain name.\\n2. Fabrikam: This also follows the same pattern.\\n\\nSo, based on the format and content of these emails:\\n- \\\"Contoso\\\" uses \\\"@contoso.com\\\"\\n- \\\"Fabrikam\\\" uses \\\"@fabrikam.com\\\"\\n\\nTherefore, the output would be:\\n- Contoso: @contoso.com\\n- Fabrikam: @fabrikam.com\"}\n","{\"output\": \"Support-response\"}\n","{\"output\": \"No.\\nExplanation:\\nThe provided instructions do not specify which step comes first or if they need to be followed in a specific sequence. There's no indication of how these steps relate to each other or what order they should be performed. Without knowing the correct sequence or relationship between the steps, we cannot determine if it's possible to follow all the instructions as written and complete the assembly. Therefore, the classification is \\\"No\\\".\"}\n","{\"output\": \"NO\"}\n","{\"output\": \"There are no errors in this passage. It follows standard English grammar rules and uses appropriate vocabulary and spelling.\"}\n","{\"output\": \"To determine if the two given strings are anagrams of each other, we need to check if both strings contain exactly the same characters in any order. Here's how I would approach this:\\n\\n1. Convert both strings to lowercase for case-insensitive comparison.\\n2. Sort the characters in each string alphabetically.\\n3. Compare the sorted versions of the strings.\\n\\nLet's apply these steps to the provided example:\\n\\nOriginal strings:\\n- daneel olivaw\\n- leviaw dna eela\\n\\nStep 1: Convert to lowercase\\n- Both strings are already in lowercase.\\n\\nStep 2 & 3: \\n- Sorting \\\"\"}\n","{\"output\": \"To determine if \\\"abc\\\" is a subsequence of \\\"ahbgdc\\\", we need to check each character in \\\"abc\\\" against the corresponding positions in \\\"ahbgdc\\\". If all characters match and there's no mismatch, then \\\"abc\\\" is a subsequence.\\n\\nLet's go through this step-by-step:\\n\\n1. Compare 'a' in \\\"abc\\\" with 'a' in \\\"ahbgdc\\\":\\n   - True\\n\\n2. Compare 'b' in \\\"abc\\\" with 'b' in \\\"ahbgdc\\\":\\n   - False\\n\\n3. Compare 'c' in \\\"abc\\\" with 'c' in \\\"\"}\n","{\"output\": \"Based on the content of both sentences, they do not provide enough information to definitively determine which sentiment is more positive (POSITIVE) or negative (NEGATIVE). Both sentences describe experiences with poor service and cold food, but there's no clear indication of overall satisfaction or enthusiasm from either review. Therefore, it would be best to use context clues or additional information about the reviewer's experience to make a judgment.\"}\n","{\"output\": \"Based on the plot summary provided in Passage 2, which describes a positive outcome for the protagonist, I would classify this as:\\nPOSITIVE\"}\n","{\"output\": \"No\"}\n","\n"]}],"source":["print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Z_nUaV4gxQm","outputId":"9767c028-bd89-4887-90a5-2d8542ba4e61","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732146938266,"user_tz":480,"elapsed":5,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["14752"]},"metadata":{},"execution_count":9}],"source":["Path(\"output.txt\").write_text(output.stdout)"]},{"cell_type":"markdown","metadata":{"id":"HtsOBru5gxQm"},"source":["## Evaluate the default output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpfH7SICgxQn","outputId":"b27f1441-7c08-4742-af5f-775e79a21497","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732146938266,"user_tz":480,"elapsed":2,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Score=28.0000\n"]}],"source":["!python ../output_check.py -t ../data/reference/dev.out -o output.txt"]},{"cell_type":"markdown","metadata":{"id":"Pkcd6X4TgxQn"},"source":["Ignore the huggingface warnings."]},{"cell_type":"markdown","metadata":{"id":"MXjvpyPcgxQo"},"source":["## Documentation\n","\n","Write some beautiful documentation of your program here."]},{"cell_type":"markdown","metadata":{"id":"P68Oq-sxgxQo"},"source":["## Analysis\n","\n","Do some analysis of the results. What ideas did you try? What worked and what did not?"]},{"cell_type":"markdown","source":["#### merge our train dataset as one for handiness"],"metadata":{"id":"IaX3MfQM1wb1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmesPAmUgxQo","outputId":"32460fbd-9be3-4f9b-bbd5-206ebeee450b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732143701314,"user_tz":480,"elapsed":2574,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Merging completed. Merged file saved to ../data/train_merged.json\n"]}],"source":["def is_gzipped(file_path):\n","    return file_path.endswith('.gz')\n","\n","def open_file(file_path, mode='rt'):\n","    if is_gzipped(file_path):\n","        return gzip.open(file_path, mode, encoding='utf-8')\n","    else:\n","        return open(file_path, mode, encoding='utf-8')\n","\n","def merge_train_files(train_txt_path, train_out_path, output_path):\n","    with open_file(train_txt_path, 'rt') as txt_file, \\\n","         open_file(train_out_path, 'rt') as out_file, \\\n","         open(output_path, 'w', encoding='utf-8') as merged_file:\n","\n","        txt_line_num = 0\n","        out_line_num = 0\n","\n","        for txt_line, out_line in zip(txt_file, out_file):\n","            txt_line_num += 1\n","            out_line_num += 1\n","\n","            try:\n","                txt_json = json.loads(txt_line.strip())\n","                out_json = json.loads(out_line.strip())\n","\n","                merged_json = {\n","                    \"prompt\": txt_json.get(\"prompt\", \"\"),\n","                    \"constraints\": txt_json.get(\"constraints\", \"\"),\n","                    \"output\": out_json.get(\"output\", \"\")\n","                }\n","\n","                merged_file.write(json.dumps(merged_json) + '\\n')\n","\n","            except json.JSONDecodeError as e:\n","                print(f\"JSON decode error at line {txt_line_num} or {out_line_num}: {e}\")\n","            except Exception as e:\n","                print(f\"Unexpected error at line {txt_line_num} or {out_line_num}: {e}\")\n","\n","    print(f\"Merging completed. Merged file saved to {output_path}\")\n","\n","\n","data_dir = '../data'\n","train_txt = os.path.join(data_dir, 'train.txt')  # or 'train.txt' if not compressed\n","train_out = os.path.join(data_dir, 'train.out')  # or 'train.out' if not compressed\n","merged_output = os.path.join(data_dir, 'train_merged.json')\n","\n","# Call the merge function\n","merge_train_files(train_txt, train_out, merged_output)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wi4ZZeMFgxQp"},"outputs":[],"source":["def open_file(file_path, mode='rt'):\n","    return open(file_path, mode, encoding='utf-8')\n","\n","def extract_unique_constraints(merged_file_path):\n","    constraints_set = set()\n","    constraints_count = defaultdict(int)\n","    total_lines = 0\n","    skipped_lines = 0\n","\n","    with open_file(merged_file_path, 'rt') as file:\n","        for line_num, line in enumerate(file, 1):\n","            total_lines += 1\n","            line = line.strip()\n","            if not line:\n","                print(f\"Skipping empty line at {line_num}.\")\n","                skipped_lines += 1\n","                continue\n","            try:\n","                data = json.loads(line)\n","                constraint = data.get(\"constraints\", \"\").strip()\n","                if constraint:\n","                    constraints_set.add(constraint)\n","                    constraints_count[constraint] += 1\n","                else:\n","                    print(f\"No constraints found at line {line_num}.\")\n","                    skipped_lines += 1\n","            except json.JSONDecodeError as e:\n","                print(f\"JSON decode error at line {line_num}: {e}\")\n","                skipped_lines += 1\n","            except Exception as e:\n","                print(f\"Unexpected error at line {line_num}: {e}\")\n","                skipped_lines += 1\n","\n","    return constraints_set, constraints_count, total_lines, skipped_lines\n","\n","# data_dir = '../data'\n","# merged_file = 'train_merged.json'\n","\n","# # Construct the full file path\n","# merged_file_path = Path(data_dir) / merged_file"]},{"cell_type":"markdown","metadata":{"id":"eL_xnsl21Ig4"},"source":["### Check how many unique constraints and counts in train set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHjuxcg0gxQp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732143707143,"user_tz":480,"elapsed":420,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"7bb2772d-52b8-4eb5-90d6-073185e7db02"},"outputs":[{"output_type":"stream","name":"stdout","text":["No constraints found at line 829.\n","No constraints found at line 976.\n","No constraints found at line 1507.\n","No constraints found at line 2296.\n","No constraints found at line 3477.\n","No constraints found at line 3496.\n","No constraints found at line 3704.\n","No constraints found at line 4900.\n","No constraints found at line 5033.\n","No constraints found at line 7499.\n","No constraints found at line 9213.\n","No constraints found at line 13714.\n","No constraints found at line 15246.\n","No constraints found at line 18577.\n","No constraints found at line 22345.\n","No constraints found at line 25073.\n","No constraints found at line 26996.\n","No constraints found at line 27550.\n","No constraints found at line 29867.\n","No constraints found at line 34328.\n","No constraints found at line 38539.\n","No constraints found at line 43049.\n","No constraints found at line 43412.\n","No constraints found at line 54880.\n","No constraints found at line 55870.\n","No constraints found at line 56195.\n","No constraints found at line 57125.\n","No constraints found at line 61048.\n","Total lines processed: 68478\n","Total lines skipped due to errors or missing constraints: 28\n","Total unique constraints found: 29368\n","\n"]}],"source":["constraints_set, constraints_count, total_lines, skipped_lines = extract_unique_constraints(merged_file_path)\n","\n","print(f\"Total lines processed: {total_lines}\")\n","print(f\"Total lines skipped due to errors or missing constraints: {skipped_lines}\")\n","print(f\"Total unique constraints found: {len(constraints_set)}\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAlskStzgxQq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732143722723,"user_tz":480,"elapsed":230,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"8aee1ad1-1579-4b01-f484-8dee688f9a7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique Constraints (Sorted by Frequency)\n","None (Count: 14457)\n","None. (Count: 4678)\n","The output should be 'True' or 'False'. (Count: 2712)\n","The output should be 'Yes' or 'No'. (Count: 2102)\n","The output should be one of the two: 'Yes' or 'No'. (Count: 1121)\n","The output should be one of the two: 'True' or 'False'. (Count: 909)\n","The output should be an integer. (Count: 726)\n","The output should be 'POSITIVE' or 'NEGATIVE'. (Count: 674)\n","The output should be 0 or 1. (Count: 599)\n","The output should be 'YES' or 'NO'. (Count: 394)\n","The output should be one of the three: 'stereotype', 'anti-stereotype' or 'unrelated'. (Count: 387)\n","The output should be one of the following characters: 'A', 'B, 'C', 'D'. (Count: 318)\n","The output should be either 'True' or 'False'. (Count: 177)\n","The output should be 'NEGATIVE'. (Count: 177)\n","The output should be 'POSITIVE', 'NEGATIVE' or 'NEUTRAL'. (Count: 174)\n","The output should be one of the following characters: 'A', 'B, 'C', or 'D'. (Count: 158)\n","The output should be 'A' or 'B'. (Count: 132)\n","The output should be 0 (False) or 1 (True). (Count: 130)\n","The output should be a string. (Count: 111)\n","The output should be either 'true' or 'false'. (Count: 103)\n","The output should be a number between 0 and 9. (Count: 101)\n","The output should be a positive integer. (Count: 97)\n","The output should be one of two values: 'Yes' or 'No'. (Count: 93)\n","The output should be either 'Yes' or 'No'. (Count: 91)\n","The output should be 'SAVORY' or 'SWEET'. (Count: 90)\n","The output should be one of the following characters: 'A', 'B, 'C'. (Count: 82)\n","The output should be a single word. (Count: 79)\n","The output should be one of the two words: 'Yes' or 'No'. (Count: 73)\n","The output should be 'TRUE' or 'FALSE'. (Count: 73)\n","The answer should be 0 or 1. (Count: 73)\n","The output should be one of three values - 'stereotype', 'anti-stereotype' or 'unrelated'. (Count: 72)\n","The output should be 'A', 'B', 'C' or 'D'. (Count: 70)\n","The output should be one of the two strings: \"Yes\" or \"No\". (Count: 69)\n",": None (Count: 62)\n","The output should be a number. (Count: 61)\n","The output should be 'yes' or 'no'. (Count: 61)\n","The output should be either 'yes' or 'no'. (Count: 61)\n","The output should be one of the two values: 'True' or 'False'. (Count: 60)\n","The answer should be correct to one decimal place. (Count: 60)\n","The output should be one of the two strings: 'Yes' or 'No'. (Count: 59)\n","The output should be one of the following characters: 'A', 'B', 'C', or 'D'. (Count: 58)\n","The output should be one of the following characters: 'A', 'B', 'C'. (Count: 57)\n","The output should be 'true' or 'false'. (Count: 56)\n","The output should be one word. (Count: 55)\n","Output should be 'Yes' or 'No'. (Count: 55)\n","The output should be 'A', 'B', or 'C'. (Count: 54)\n","The output must consist of the numbers representing the sentences. (Count: 54)\n","The output should be 'POSITIVE', 'NEGATIVE', or 'NEUTRAL'. (Count: 54)\n","The output should be one string. (Count: 51)\n","The output should be one word only. (Count: 50)\n"]}],"source":["# Sort constraints by occurrence count in descending order\n","sorted_constraints = sorted(constraints_count.items(), key=lambda item: item[1], reverse=True)\n","\n","print(\"Unique Constraints (Sorted by Frequency)\")\n","for i, (constraint, count) in enumerate(sorted_constraints):\n","    if i >= 50:\n","        break  # Stop after printing 500 values\n","    print(f\"{constraint} (Count: {count})\")"]},{"cell_type":"markdown","source":["### check how many unique values of constraints in our dev and test sets"],"metadata":{"id":"UEQXtvm62X1m"}},{"cell_type":"code","source":["constraints_set, constraints_count, total_lines, skipped_lines = extract_unique_constraints('../data/input/dev.txt')\n","\n","print(f\"Total lines processed: {total_lines}\")\n","print(f\"Total lines skipped due to errors or missing constraints: {skipped_lines}\")\n","print(f\"Total unique constraints found: {len(constraints_set)}\\n\")\n","# Sort constraints by occurrence count in descending order\n","sorted_constraints = sorted(constraints_count.items(), key=lambda item: item[1], reverse=True)\n","\n","print(\"Unique Constraints (Sorted by Frequency)\")\n","for i, (constraint, count) in enumerate(sorted_constraints):\n","    if i >= 50:\n","        break  # Stop after printing 500 values\n","    print(f\"{constraint} (Count: {count})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtJx8c8k2Yii","executionInfo":{"status":"ok","timestamp":1732161336502,"user_tz":480,"elapsed":1015,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"088f0882-d8fc-4b2a-b5f1-fe4649767b0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total lines processed: 100\n","Total lines skipped due to errors or missing constraints: 0\n","Total unique constraints found: 64\n","\n","Unique Constraints (Sorted by Frequency)\n","The output should be 'True' or 'False'. (Count: 11)\n","The output should be 'Yes' or 'No'. (Count: 8)\n","None (Count: 8)\n","The output should be one of the two: 'Yes' or 'No'. (Count: 7)\n","None. (Count: 3)\n","The output should be 'POSITIVE' or 'NEGATIVE'. (Count: 3)\n","The output should be one of the two: 'True' or 'False'. (Count: 2)\n","The output should be one of the following characters: 'A', 'B', 'C'. (Count: 2)\n","The output should be an integer between -5 and 5. (Count: 1)\n","The output should be a single word. (Count: 1)\n","The output should be 'Pizza', 'Hamburger', or 'Sandwich'. (Count: 1)\n","The output should be one word: either True or False (Count: 1)\n","The output should be 'POSITIVE', 'NEGATIVE', or 'NEUTRAL'. (Count: 1)\n","The output should be one of the following labels: 'complaint', 'inconvenience', 'incident'. (Count: 1)\n","The output should be one of the two:'Yes' or 'No'. (Count: 1)\n","The output should be one of the following characters: 'A', 'B' ,'C', or 'D'. (Count: 1)\n","The output should be 'POSITIVE', 'MIXED', or 'NEGATIVE'. (Count: 1)\n","The array should be sorted in non-decreasing order. (Count: 1)\n","The output should be 'argumentative' or 'not_argumentative'. (Count: 1)\n","The output should be 'Incorrect' or 'Correct'. (Count: 1)\n","The output should be one of the following letters: 'N', 'V', 'A', 'P' or 'I'. (Count: 1)\n","Output should be 0 or 1. (Count: 1)\n","Output should be 'True'. (Count: 1)\n","The output should be either 'noun' or 'adjective'. (Count: 1)\n","The output should be exactly one of the four strings provided above. (Count: 1)\n","The output should be either 'true' or 'false'. (Count: 1)\n","The output should be either 'first', 'second' or 'unrelated'. (Count: 1)\n","The output should be one of the following integers: 1, 2, 3. (Count: 1)\n","The output should be 'A', 'B', 'C' or 'D'. (Count: 1)\n","The output should be either 'Yes' or 'No'. (Count: 1)\n","The output should be one feeling word such as 'happy', 'sad', 'angry'. (Count: 1)\n","The output should be 0 (False) or 1 (True). (Count: 1)\n","The output should be one of three values - 'synonym', 'antonym' or 'none'. (Count: 1)\n","The output should be one of the two: 'Causal' or 'Not Causal'. (Count: 1)\n","The output should be one of three strings as specified above. (Count: 1)\n","The output should be 'dog' or 'owner'. (Count: 1)\n","The output must consist of the numbers representing the sentences (Count: 1)\n","The output should be 'FORMAL' or 'INFORMAL'. (Count: 1)\n","The output should be one of the two strings 'Yes' or 'No'. (Count: 1)\n","The output should be one of the two values: 'True' or 'False'. (Count: 1)\n","The output should be 'Summary1' or 'Summary2'. (Count: 1)\n","The output should be one of the two for each sentence in the order they are given: 'Credible' or 'Not credible'. (Count: 1)\n","The output should be one of the following characters: 'A', 'B, 'C', 'D'. (Count: 1)\n",": The output should be a string consisting of numbers representing the sentences in order (e12345). (Count: 1)\n","The output should be one of the two strings 'Clockwise' or 'Counterclockwise'. (Count: 1)\n","The output should be one of the following characters: 'A', 'B', 'C', or 'D'. (Count: 1)\n","The output should consist of numbers representing the sentences in sequential order. (Count: 1)\n","The output should be ' temporal' or ' None'. (Count: 1)\n","The output should be one of the three: 'stereotype', 'anti-stereotype' or 'unrelated'. (Count: 1)\n","The output should list the required substeps for each step in order, such as '1),2),3),4)' or '1a),1b)' etc., or 'None' if there are no required substeps for that step. (Count: 1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"uNqfmSBSgxQq"},"source":["### First, we use train_default.out to compare with the output in train.out with fussywussy, if they are too different, then we add it into our ORPO dataset."]},{"cell_type":"code","source":["# asking another LM to be our judge to create ORPO dataset is too slow,\n","# so we want to replace that judge with simpler string comparison methods like fuzzywuzzy\n","# from https://www.geeksforgeeks.org/fuzzywuzzy-python-library/\n","\n","# def preprocess_text(text):\n","#     # Convert to lowercase\n","#     # text = text.lower()\n","#     # Remove punctuation\n","#     text = re.sub(r'[^\\w\\s]', '', text)\n","#     # Remove extra whitespace\n","#     text = ' '.join(text.split())\n","#     return text"],"metadata":{"id":"FAcST0Simg-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KLFVPmtnOELJ"},"outputs":[],"source":["# s1 = \"Yes\"\n","# s2 = \"\"\"To determine if the given list of words forms a palindrome, we can compare each word with its reverse:\n","\n","# 1. 'b' (reverse of 'b') = 'b'\n","# 2. 'a' (reverse of 'a') = 'a'\n","# 3. 'n' (reverse of 'n') = 'n'\n","\n","# Since all pairs of words have the same reversed version, the entire list reads the same forwards and backwards.\n","\n","# Output: Yes\"\"\"\n","# s1 = preprocess_text(s1)\n","# s2 = preprocess_text(s2)\n","# print(s1, \"\\n\", s2)\n","# print(\"FuzzyWuzzy Ratio: \", fuzz.ratio(s1, s2))\n","# print(\"FuzzyWuzzy PartialRatio: \", fuzz.partial_ratio(s1, s2))\n","# print(\"FuzzyWuzzy TokenSortRatio: \", fuzz.token_sort_ratio(s1, s2))\n","# print(\"FuzzyWuzzy TokenSetRatio: \", fuzz.token_set_ratio(s1, s2))\n","# print(\"FuzzyWuzzy WRatio: \", fuzz.WRatio(s1, s2),'\\n\\n')\n","\n","# query = 'geeks for geeks'\n","# choices = ['geek for geek', 'geek geek', 'g. for geeks']\n","# print (\"List of ratios: \")\n","# print (process.extract(query, choices), '\\n')\n","# print (\"Best among the above list: \",process.extractOne(query, choices))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1732143854889,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"biZkCHdVgxQq","outputId":"b07a2dea-1db2-493a-dfdd-6b768f69a5b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["../data/train_merged.json\n","../data/train_default.out\n"]}],"source":["# # Paths to your datasets\n","# data_dir = '../data'  # Update this path if necessary\n","# merged_file = 'train_merged.json'  # Your original dataset\n","# default_file = 'train_default.out'  # The new dataset from your professor\n","\n","# # Construct the full file paths\n","# merged_file_path = Path(data_dir) / merged_file\n","# default_file_path = Path(data_dir) / default_file\n","\n","# # Check if the files exist\n","# print(merged_file_path)\n","# print(default_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2vDpqHjgxQq"},"outputs":[],"source":["# orpo_dataset_dict = {\n","#     \"prompt\": [],\n","#     \"chosen\": [],\n","#     \"rejected\": []\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91740,"status":"ok","timestamp":1732074203829,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"I5D8PZpNgxQq","outputId":"bdbee6fd-1677-426e-cb97-cd907c7984bc"},"outputs":[{"output_type":"stream","name":"stderr","text":["Processing samples: 100%|██████████| 68478/68478 [01:30<00:00, 759.59it/s]\n"]}],"source":["# similarity_threshold = 50\n","\n","# extreme_values = [\"None\", \"None.\", \": None\", \"N/A\", \"Yes\", \"none\", \"-\", \":None\", \"No\", \"yes\", \"no\"]\n","\n","# # Open both datasets\n","# with open(merged_file_path, 'rt', encoding='utf-8') as merged_f, \\\n","#      open(default_file_path, 'rt', encoding='utf-8') as default_f:\n","\n","#     merged_lines = merged_f.readlines()\n","#     default_lines = default_f.readlines()\n","\n","#     # Iterate over the datasets\n","#     for line_num, (merged_line, default_line) in enumerate(tqdm(zip(merged_lines, default_lines), desc=\"Processing samples\", total=len(merged_lines)), 1):\n","#         try:\n","#             # Read data from merged dataset\n","#             merged_data = json.loads(merged_line.strip())\n","#             prompt = merged_data.get('prompt', '')\n","#             constraints = merged_data.get('constraints', '')\n","#             output_merged = merged_data.get('output', '').strip()\n","\n","#             if constraints.strip() in extreme_values:\n","#                 continue\n","\n","#             # Read data from default dataset\n","#             default_data = json.loads(default_line.strip())\n","#             output_default = default_data.get('output', '').strip()\n","\n","#             # Preprocess the outputs\n","#             output_merged_clean = preprocess_text(output_merged)\n","#             output_default_clean = preprocess_text(output_default)\n","\n","#             # Compute similarity\n","#             similarity_score_WRatio = fuzz.WRatio(output_merged_clean, output_default_clean)\n","#             similarity_score_TokenSetRatio = fuzz.token_set_ratio(output_merged_clean, output_default_clean)\n","\n","#             if similarity_score_WRatio < similarity_threshold and similarity_score_TokenSetRatio < similarity_threshold:\n","#                 # Outputs are significantly different; add to ORPO dataset\n","\n","#                 prompt_text = prompt + '\\n' + constraints\n","#                 messages = [\n","#                     {\n","#                         \"role\": \"system\",\n","#                         \"content\": \"You are a helpful assistant that provides useful answers without too much extra output.\",\n","#                     },\n","#                     {\n","#                         \"role\": \"user\",\n","#                         \"content\": f\"{prompt_text}\"\n","#                     },\n","#                 ]\n","\n","#                 orpo_dataset_dict['prompt'].append(messages)\n","#                 orpo_dataset_dict['chosen'].append(output_merged)\n","#                 orpo_dataset_dict['rejected'].append(output_default)\n","\n","#         except Exception as e:\n","#             print(f\"Error processing line {line_num}: {e}\")\n","#             continue\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":445,"status":"ok","timestamp":1732074222185,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"rCHbyFiwgxQr","outputId":"96a29029-f211-40f0-974d-c0334c98e14e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total entries in orpo_dataset_dict: 15312\n","\n","Entry 1:\n","Prompt: [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': \"In this task, you are given a passage of text with tags separating each sentence. Your job is to return the number of the sentence that contains an error in grammar or spelling. If there are no errors, return 'No Error'.\\nNo<sep>error<sep>.\\nThe output should be a number or 'No Error'.\"}]\n","Chosen (Output from merged dataset): No Error\n","Rejected (Output from default dataset): 1\n","--------------------------------------------------\n","\n","Entry 2:\n","Prompt: [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': \"A palindrome is a word that reads the same forward and backward, e.g., madam or level.\\nnoon.\\nThe output should be 'True' or 'False'.\"}]\n","Chosen (Output from merged dataset): True\n","Rejected (Output from default dataset): To determine if a given string is a palindrome, you can compare characters from the beginning with those from the end moving towards the center of the string. If all corresponding characters match, the string is a palindrome.\n","\n","Here's how you can implement this in Python:\n","\n","```python\n","def is_palindrome(s):\n","    # Remove spaces and convert to lowercase for uniformity\n","    cleaned_s = ''.join(c.lower() for c in s if c.isalnum())\n","    \n","    # Compare characters from both ends moving towards the center\n","    return cleaned_s == cleaned_s[::-1]\n","\n","# Test cases\n","print(is_palindrome(\"madam\"))  #\n","--------------------------------------------------\n","\n","Entry 3:\n","Prompt: [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': \"Given two sentences, determine whether they are cooperative or not. Two sentences are cooperative if the first one is a question and the second sentence is its answer.\\nDid you see that movie?, I didn't see it.\\nThe output should be 'True' or 'False'.\"}]\n","Chosen (Output from merged dataset): False\n","Rejected (Output from default dataset): To determine if these sentences are cooperative, we need to analyze their structure:\n","\n","1. The first sentence \"Did you see that movie? \" is asking about seeing something (the movie).\n","2. The second sentence \"I didn't see it\" is answering this same question.\n","\n","Since both sentences are essentially asking the same thing (\"did you see that movie? \"), they are indeed cooperative.\n","\n","Output: True\n","--------------------------------------------------\n","\n","Entry 4:\n","Prompt: [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'In this task, you will be given a list of sentences. You have to determine whether each sentence is \"FACTUAL\" or \"OPINIONATED\". A factual sentence states something that can be verified as true or false. An opinionated sentence expresses someone\\'s beliefs, thoughts, feelings, or emotions.\\nSentence1: The sun is a star. Sentence2: I think the sun is beautiful.\\nThe output should be \\'FACTUAL\\' or \\'OPINIONATED\\'.'}]\n","Chosen (Output from merged dataset): Sentence1: FACTUAL\n","Sentence2: OPINIONATED\n","Rejected (Output from default dataset): Factored.\n","--------------------------------------------------\n","\n","Entry 5:\n","Prompt: [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'In this task, you are given a collection of tweets. The task is to classify each tweet as \"POSITIVE\", \"NEGATIVE\" or \"NEUTRAL\".\\nSentiment140 dataset with 1.6 million tweets.\\nThe output should be \\'POSITIVE\\', \\'NEGATIVE\\' or \\'NEUTRAL\\'.'}]\n","Chosen (Output from merged dataset): The tweets have been annotated (0 = negative, 2 = neutral, 4 = positive) and they can be used to detect sentiment.\n","\n","For example, the tweet \"I love cats\" would be classified as \"POSITIVE\", while the tweet \"I hate cats\" would be classified as \"NEGATIVE\".\n","\n","The tweets in this dataset have been pre-processed and the text has been lowercased.\n","Rejected (Output from default dataset): Based on the information provided in the instruction and the content of the tweets listed, I would classify this as:\n","\n","**POSITIVE**\n","\n","This classification aligns with the positive sentiment expressed in the tweets about various topics such as politics, science, technology, and general interest. There are no negative comments or criticisms mentioned in the text.\n","--------------------------------------------------\n"]}],"source":["# # Print the total number of entries\n","# total_entries = len(orpo_dataset_dict['prompt'])\n","# print(f\"Total entries in orpo_dataset_dict: {total_entries}\")\n","\n","# # Define the number of random samples you want\n","# num_samples = 5\n","\n","# # Adjust the number of samples if there are fewer than 5 entries\n","# if total_entries < num_samples:\n","#     num_samples = total_entries\n","#     print(f\"Only {num_samples} entries available. Displaying all available entries.\")\n","\n","# # Select random unique indices without replacement\n","# random_indices = random.sample(range(total_entries), num_samples)\n","\n","# # Print the selected random entries\n","# for i, idx in enumerate(random_indices, 1):\n","#     print(f\"\\nEntry {i}:\")\n","#     print(f\"Prompt: {orpo_dataset_dict['prompt'][idx]}\")\n","#     print(f\"Chosen (Output from merged dataset): {orpo_dataset_dict['chosen'][idx]}\")\n","#     print(f\"Rejected (Output from default dataset): {orpo_dataset_dict['rejected'][idx]}\")\n","#     print('-' * 50)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1350,"status":"ok","timestamp":1732074327610,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"WK1lNBeNgxQr","outputId":"e5d930d4-cd3c-4ff6-ed98-abe7d2626957"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ORPO dataset saved to ../data/orpo.json\n"]}],"source":["# # Save to a JSON file\n","# orpo_output_path = Path(data_dir) / 'orpo_original.json'\n","\n","# with open(orpo_output_path, 'w', encoding='utf-8') as out_file:\n","#     json.dump(orpo_dataset_dict, out_file, indent=4)\n","\n","# print(f\"\\nORPO dataset saved to {orpo_output_path}\")\n"]},{"cell_type":"markdown","source":["### Final ORPO dataset"],"metadata":{"id":"XYfQvjuDXbVW"}},{"cell_type":"code","source":["def preprocess_text(text):\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Remove punctuation\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    # Remove extra whitespace\n","    text = ' '.join(text.split())\n","    return text"],"metadata":{"id":"h4paa0g5Xm4q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paths to your datasets\n","data_dir = '../data'  # Update this path if necessary\n","merged_file = 'train_merged.json'  # Your original dataset\n","default_file = 'train_default.out'  # The new dataset from your professor\n","\n","# Construct the full file paths\n","merged_file_path = Path(data_dir) / merged_file\n","default_file_path = Path(data_dir) / default_file\n","\n","# Check if the files exist\n","print(merged_file_path)\n","print(default_file_path)"],"metadata":{"id":"w3DUpy5GXnlQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732228812531,"user_tz":480,"elapsed":183,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"4fdbb9e4-1a71-43dc-bf41-1406adaec167"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["../data/train_merged.json\n","../data/train_default.out\n"]}]},{"cell_type":"code","source":["\"\"\"\n","orpo dataset:\n","\n","add a assistant role in the orpo_original dataset with content = [chosen] or [rejected] answers\n","\n","\"\"\"\n","\n","orpo_dataset_dict = {\n","    \"chosen\": [],\n","    \"rejected\": []\n","}"],"metadata":{"id":"miD9JFq9WkpA","executionInfo":{"status":"ok","timestamp":1732228811380,"user_tz":480,"elapsed":176,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# similarity_threshold = 50\n","\n","# extreme_values = [\"None\", \"None.\", \": None\", \"N/A\", \"Yes\", \"none\", \"-\", \":None\", \"No\", \"yes\", \"no\"]\n","\n","# Open both datasets\n","with open(merged_file_path, 'rt', encoding='utf-8') as merged_f, \\\n","     open(default_file_path, 'rt', encoding='utf-8') as default_f:\n","\n","    merged_lines = merged_f.readlines()\n","    default_lines = default_f.readlines()\n","\n","    # Iterate over the datasets\n","    for line_num, (merged_line, default_line) in enumerate(tqdm(zip(merged_lines, default_lines), desc=\"Processing samples\", total=len(merged_lines)), 1):\n","        try:\n","            # Read data from merged dataset\n","            merged_data = json.loads(merged_line.strip())\n","            prompt = merged_data.get('prompt', '')\n","            constraints = merged_data.get('constraints', '')\n","            output_merged = merged_data.get('output', '').strip()\n","\n","            # if constraints.strip() in extreme_values:\n","            #     continue\n","\n","            # Read data from default dataset\n","            default_data = json.loads(default_line.strip())\n","            output_default = default_data.get('output', '').strip()\n","\n","            # Preprocess the outputs\n","            # not sure if we should pre-process them in the cleanest way\n","            # chosen = preprocess_text(output_merged)\n","            # rejected = preprocess_text(output_default)\n","            chosen = output_merged\n","            rejected = output_default\n","\n","            # Compute similarity\n","            # similarity_score_WRatio = fuzz.WRatio(chosen, rejected)\n","            # similarity_score_TokenSetRatio = fuzz.token_set_ratio(chosen, rejected)\n","\n","            # if similarity_score_WRatio < similarity_threshold and similarity_score_TokenSetRatio < similarity_threshold:\n","                # outputs (chosen and rejected) are significantly different; add to ORPO dataset\n","\n","            prompt_text = prompt + '\\n' + constraints\n","            chosen_messages = [\n","                {\n","                    \"role\": \"system\",\n","                    \"content\": \"You are a helpful assistant that provides useful answers without too much extra output.\",\n","                },\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"{prompt_text}\"\n","                },\n","                {\n","                    \"role\": \"assistant\",\n","                    \"content\": f\"{chosen}\"\n","                },\n","            ]\n","\n","            rejected_messages = [\n","                {\n","                    \"role\": \"system\",\n","                    \"content\": \"You are a helpful assistant that provides useful answers without too much extra output.\",\n","                },\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"{prompt_text}\"\n","                },\n","                {\n","                    \"role\": \"assistant\",\n","                    \"content\": f\"{rejected}\"\n","                },\n","            ]\n","\n","            # orpo_dataset_dict['prompt'].append(messages)\n","            orpo_dataset_dict['chosen'].append(chosen_messages)\n","            orpo_dataset_dict['rejected'].append(rejected_messages)\n","\n","        except Exception as e:\n","            print(f\"Error processing line {line_num}: {e}\")\n","            continue\n"],"metadata":{"id":"7zt419ZIWklq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732228816239,"user_tz":480,"elapsed":976,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"61fdc70b-b389-44d9-c85f-ae1fabc2422b"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing samples: 100%|██████████| 68478/68478 [00:00<00:00, 96025.18it/s]\n"]}]},{"cell_type":"code","source":["# Print the total number of entries\n","total_entries = len(orpo_dataset_dict['chosen'])\n","print(f\"Total entries in orpo_dataset_dict: {total_entries}\")\n","\n","# Define the number of random samples you want\n","num_samples = 5\n","\n","# Adjust the number of samples if there are fewer than 5 entries\n","if total_entries < num_samples:\n","    num_samples = total_entries\n","    print(f\"Only {num_samples} entries available. Displaying all available entries.\")\n","\n","# Select random unique indices without replacement\n","random_indices = random.sample(range(total_entries), num_samples)\n","\n","# Print the selected random entries\n","for i, idx in enumerate(random_indices, 1):\n","    print(f\"\\nEntry {i}:\")\n","    print(f\"Chosen (Output from merged dataset): {orpo_dataset_dict['chosen'][idx]}\")\n","    print(f\"Rejected (Output from default dataset): {orpo_dataset_dict['rejected'][idx]}\")\n","    print('-' * 50)"],"metadata":{"id":"iJibCFxzXsFg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732228818143,"user_tz":480,"elapsed":236,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"97e94aa0-f6bc-4e34-cab1-a32f8bbc458a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Total entries in orpo_dataset_dict: 68478\n","\n","Entry 1:\n","Chosen (Output from merged dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'In this task, you need to find the length of a string.\\n\"The quick brown fox jumps over the lazy dog\".\\nNone'}, {'role': 'assistant', 'content': 'The length of the string is 43.'}]\n","Rejected (Output from default dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'In this task, you need to find the length of a string.\\n\"The quick brown fox jumps over the lazy dog\".\\nNone'}, {'role': 'assistant', 'content': '10'}]\n","--------------------------------------------------\n","\n","Entry 2:\n","Chosen (Output from merged dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': \"You are given a target person and two sentences. Your task is to determine whether the second sentence conveys either a stereotype, anti-stereotype, or is unrelated with respect to the first sentence and the target. A stereotype is a widely held but oversimplified notion of a group of people. An anti-stereotype is an idea that goes against the widely held but oversimplified notion of a group of people. Sentences and targets are unrelated if there is no relevance between them.\\nTarget: father \\nThe father was always working late into the night. He never had time for his family.\\nThe output should be one of the three: 'stereotype', 'anti-stereotype' or 'unrelated'.\"}, {'role': 'assistant', 'content': 'stereotype'}]\n","Rejected (Output from default dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': \"You are given a target person and two sentences. Your task is to determine whether the second sentence conveys either a stereotype, anti-stereotype, or is unrelated with respect to the first sentence and the target. A stereotype is a widely held but oversimplified notion of a group of people. An anti-stereotype is an idea that goes against the widely held but oversimplified notion of a group of people. Sentences and targets are unrelated if there is no relevance between them.\\nTarget: father \\nThe father was always working late into the night. He never had time for his family.\\nThe output should be one of the three: 'stereotype', 'anti-stereotype' or 'unrelated'.\"}, {'role': 'assistant', 'content': 'Unrelated. The first sentence describes a typical workday behavior of a father, while the second sentence expresses a negative view of fathers who do not have time for their families. These ideas are completely unrelated in terms of the target (father) and the context (workday).'}]\n","--------------------------------------------------\n","\n","Entry 3:\n","Chosen (Output from merged dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'In this task, you are given sentences with words jumbled up. The task is to rearrange the words of each sentence in a way that it makes a complete and coherent sentence without changing its meaning. Only one word may be moved at a time, and every move should result in an existing English word. Generate your output using the numbers corresponding to the position of words before they have been moved. For instance, if “I like cookies” becomes “Cookies I like” after rearranging, then write “123” as the output since “I” (1) is moved ahead of “like” (2) which remains ahead of cookies (3).\\npeople usually great find here food.\\nThe output must consist of only integers from 1-5 inclusive.'}, {'role': 'assistant', 'content': '12345'}]\n","Rejected (Output from default dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'In this task, you are given sentences with words jumbled up. The task is to rearrange the words of each sentence in a way that it makes a complete and coherent sentence without changing its meaning. Only one word may be moved at a time, and every move should result in an existing English word. Generate your output using the numbers corresponding to the position of words before they have been moved. For instance, if “I like cookies” becomes “Cookies I like” after rearranging, then write “123” as the output since “I” (1) is moved ahead of “like” (2) which remains ahead of cookies (3).\\npeople usually great find here food.\\nThe output must consist of only integers from 1-5 inclusive.'}, {'role': 'assistant', 'content': '14253'}]\n","--------------------------------------------------\n","\n","Entry 4:\n","Chosen (Output from merged dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'Correct the run-on sentence.\\nThe day was hot and sunny so we decided to go to the beach to cool off, unfortunately we discovered that there was a red tide warning.\\nThe output should be a properly formatted English sentence.'}, {'role': 'assistant', 'content': 'The day was hot and sunny so we decided to go to the beach to cool off. Unfortunately, we discovered that there was a red tide warning.'}]\n","Rejected (Output from default dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': 'Correct the run-on sentence.\\nThe day was hot and sunny so we decided to go to the beach to cool off, unfortunately we discovered that there was a red tide warning.\\nThe output should be a properly formatted English sentence.'}, {'role': 'assistant', 'content': 'The day was hot and sunny, so we decided to go to the beach to cool off. Unfortunately, we discovered that there was a red tide warning.'}]\n","--------------------------------------------------\n","\n","Entry 5:\n","Chosen (Output from merged dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': \"You need to look at the given graph and determine if there is a path from node A to node C. If there is, output 'True', otherwise output 'False'.\\nGraph (as adjacency list): {'A': ['B', 'D'],\\n                                   'B': ['E', 'F'], \\n                                   'C': ['G']}.\\nThe output should be one of the two: True or False.\"}, {'role': 'assistant', 'content': 'False'}]\n","Rejected (Output from default dataset): [{'role': 'system', 'content': 'You are a helpful assistant that provides useful answers without too much extra output.'}, {'role': 'user', 'content': \"You need to look at the given graph and determine if there is a path from node A to node C. If there is, output 'True', otherwise output 'False'.\\nGraph (as adjacency list): {'A': ['B', 'D'],\\n                                   'B': ['E', 'F'], \\n                                   'C': ['G']}.\\nThe output should be one of the two: True or False.\"}, {'role': 'assistant', 'content': \"To determine if there's a path from node A to node C in the given graph, we can use Dijkstra's algorithm or simply check for connectivity between nodes A and C.\\n\\nHere's how I would approach it:\\n\\n1. Start with node A.\\n2. Check all adjacent nodes:\\n   - From A, go to B (distance 0).\\n   - Go to E (distance 1) since B has distance 0.\\n   - Go to F (distance 2) since E has distance 1.\\n   - Go to G (distance 3) since F has distance 2.\\n   \\nAll paths have been checked\"}]\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["# Save to a JSON file\n","orpo_output_path = Path(data_dir) / 'orpo.json'\n","\n","with open(orpo_output_path, 'w', encoding='utf-8') as out_file:\n","    json.dump(orpo_dataset_dict, out_file, indent=4)\n","\n","print(f\"\\nORPO dataset saved to {orpo_output_path}\")\n"],"metadata":{"id":"2R01koiAWrrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732228829641,"user_tz":480,"elapsed":3403,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"244f9dec-fbcd-4cfd-cd50-330a3bd92430"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ORPO dataset saved to ../data/orpo.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"BtQeSTVXgxQr"},"source":["### ORPO Dataset contruction idea with the data which doesn't covered in previous step\n","\n","Generate text with Qwen/Qwen2.5-0.5B-Instruct model for each sample in train_merged.jsonl file,\n","\n","and then ask model again with the prompt:\n","'You are a judge that will answer only 'yes' or 'no', by comparing A and B to judge whether A and B are the same or very similar about their meanings\n","A: [output for the sample]\n","B: [the generated new answer]\n","'\n","\n","to tell whether the output has same meaning as the generated text and then do following pipeline:\n","\n","1. if the model answered 'yes', then skip this generated text and keep generate the next answer.\n","2. if the model answered 'no', then add it into our orpo_dataset_dict as rejected answer. And the format for each line should be like this example:\n","    if the first sample in our data/train_merged.jsonl file is {\"prompt\": \"You will be given a series of words. Output these words in reverse order, with each word on its own line.\\nWords: ['Hello', 'world'].\", \"constraints\": \"None.\", \"output\": \"world\\nHello\"}.\n","    For the first sample, in the orpo_dataset_dict, we should have:\n","        orpo_dataset_dict = {\n","            \"prompt\": [\n","                \"You will be given a series of words. Output these words in reverse order, with each word on its own line.\\nWords: ['Hello', 'world'].\n","                None\",\n","                \"You will be given a series of words. Output these words in reverse order, with each word on its own line.\\nWords: ['Hello', 'world'].\n","                None\",\n","                \"You will be given a series of words. Output these words in reverse order, with each word on its own line.\\nWords: ['Hello', 'world'].\n","                None\",\n","                \"You will be given a series of words. Output these words in reverse order, with each word on its own line.\\nWords: ['Hello', 'world'].\n","                None\",\n","                \"You will be given a series of words. Output these words in reverse order, with each word on its own line.\\nWords: ['Hello', 'world'].\n","                None\",\n","            ],\n","            \"chosen\": [\n","                \"world\\nHello\",\n","                \"world\\nHello\",\n","                \"world\\nHello\",\n","                \"world\\nHello\",\n","                \"world\\nHello\"\n","            ],\n","            \"rejected\": [\n","                \"rejected answer 1\",\n","                \"rejected answer 2\",\n","                \"rejected answer 3\",\n","                \"rejected answer 4\",\n","                \"rejected answer 5\"\n","            ],\n","        }\n","3. if the model answered something else other than 'yes' and 'no', then skip this generated text and keep generate the next answer.\n","4. check if we already have 5 rejected answers, if we already have 5 rejected answers, then go to next sample in our data/train_merged.jsonl file\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aBSuxNtQ1m9W"},"source":["### But unfortunately, this is way too time-consuming, so we just omit this dataset generation technique for the rest of data and will use what we have from train_default"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C38ExczugxQr"},"outputs":[],"source":["# model_name = 'Qwen/Qwen2.5-0.5B-Instruct'\n","\n","# # Load the tokenizer and model\n","# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","# model = AutoModelForCausalLM.from_pretrained(\n","#     model_name,\n","#     device_map='auto',\n","#     torch_dtype=torch.bfloat16,\n","#     trust_remote_code=True\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJ-jbuQkgxQs"},"outputs":[],"source":["# device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n","# model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UGn6y_tgxQs"},"outputs":[],"source":["# from transformers import StoppingCriteria, StoppingCriteriaList\n","\n","# class StopOnTokens(StoppingCriteria):\n","#     def __init__(self, stop_tokens, tokenizer):\n","#         self.stop_tokens = stop_tokens\n","#         self.tokenizer = tokenizer\n","\n","#     def __call__(self, input_ids, scores, **kwargs):\n","#         last_token_id = input_ids[0, -1].item()\n","#         if last_token_id in self.stop_tokens:\n","#             return True\n","#         return False\n","\n","# def generate_answer(prompt, max_new_tokens=128, temperature=0.7, stop_tokens=None):\n","#     input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n","\n","#     # Generate the output with stopping criteria\n","#     output_ids = model.generate(\n","#         input_ids,\n","#         max_new_tokens=max_new_tokens,\n","#         do_sample=True,\n","#         temperature=temperature,\n","#         top_p=0.95,\n","#         eos_token_id=tokenizer.eos_token_id,\n","#         pad_token_id=tokenizer.eos_token_id,\n","#         stopping_criteria=StoppingCriteriaList([StopOnTokens(stop_tokens, tokenizer)]) if stop_tokens else None\n","#     )\n","#     # Remove the prompt from the output to get only the generated text\n","#     generated_tokens = output_ids[0][input_ids.shape[-1]:]\n","#     new_answer = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n","#     return new_answer.strip()\n","\n","\n","# def clean_generated_text(generated_text):\n","#     unwanted_phrases = [\"```\", \"Human:\", \"Assistant:\", \"### Response:\", \"### Instruction:\"]\n","#     for phrase in unwanted_phrases:\n","#         generated_text = generated_text.replace(phrase, '')\n","#     return generated_text.strip()\n","\n","# # Define stop tokens\n","# stop_tokens = [tokenizer.encode(token, add_special_tokens=False)[0] for token in ['\\n', '<|endoftext|>']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xw_dyQWOgxQs"},"outputs":[],"source":["# orpo_dataset_dict = {\n","#     \"prompt\": [],\n","#     \"chosen\": [],\n","#     \"rejected\": []\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B1EONQL5gxQs","outputId":"fef29697-2df0-48e7-b4d1-98fe5a1b62e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded existing ORPO dataset with 24324 entries.\n"]}],"source":["# # Define the directory and file names\n","# data_dir = '../data'  # Update this path if necessary\n","# orpo_file = 'orpo_dataset_from_train_default.json'\n","\n","# # Construct the full file path\n","# orpo_file_path = Path(data_dir) / orpo_file\n","\n","# # Initialize the ORPO dataset dictionary\n","# if orpo_file_path.exists():\n","#     with open(orpo_file_path, 'r', encoding='utf-8') as orpo_f:\n","#         orpo_dataset_dict = json.load(orpo_f)\n","#     print(f\"Loaded existing ORPO dataset with {len(orpo_dataset_dict['prompt'])} entries.\")\n","# else:\n","#     orpo_dataset_dict = {\n","#         \"prompt\": [],\n","#         \"chosen\": [],\n","#         \"rejected\": []\n","#     }\n","#     print(\"Initialized an empty ORPO dataset.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lO8jsMEagxQs","outputId":"d0ce3778-2beb-4dbd-b934-c6c22224f250"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique prompts in ORPO dataset: 24324\n"]}],"source":["# # Create a set of existing prompts to avoid duplicates\n","# existing_prompts = set(orpo_dataset_dict['prompt'])\n","# print(f\"Number of unique prompts in ORPO dataset: {len(existing_prompts)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"js2Jxp7UgxQs","outputId":"0aca4f3d-fbc6-462d-a759-5c8db4a9311c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Merged File: ../data/train_merged.jsonl\n","Train Default File: ../data/train_default.out\n"]}],"source":["# # Paths to your datasets\n","# merged_file = 'train_merged.jsonl'    # Your original dataset\n","# default_file = 'train_default.out'    # The new dataset from your professor\n","\n","# # Construct the full file paths\n","# merged_file_path = Path(data_dir) / merged_file\n","# default_file_path = Path(data_dir) / default_file\n","\n","# # Check if the files exist\n","# if not merged_file_path.exists():\n","#     raise FileNotFoundError(f\"The file {merged_file_path} does not exist. Please check the path.\")\n","# if not default_file_path.exists():\n","#     raise FileNotFoundError(f\"The file {default_file_path} does not exist. Please check the path.\")\n","\n","# print(f\"Train Merged File: {merged_file_path}\")\n","# print(f\"Train Default File: {default_file_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gt_slKPHgxQt"},"outputs":[],"source":["# similarity_threshold = 70\n","\n","# with open(merged_file_path, 'rt', encoding='utf-8') as f:\n","#     for line_num, line in enumerate(tqdm(f, desc=\"Processing samples\"), 1):\n","#         line = line.strip()\n","#         if not line:\n","#             continue\n","#         try:\n","#             data = json.loads(line)\n","#             prompt = data.get('prompt', '')\n","\n","#             if prompt in existing_prompts:\n","#                 continue\n","\n","#             constraints = data.get('constraints', '')\n","#             output = data.get('output', '').strip()\n","\n","#             combined_prompt = (\n","#                 f\"{prompt}\\n\"\n","#                 f\"Constraints: {constraints}\\n\"\n","#                 \"Provide the output as per the instructions above without any additional text.\"\n","#             )\n","\n","#             # Initialize rejected answers list\n","#             rejected = []\n","\n","#             max_attempts = 3  # Prevent infinite loops\n","#             attempts = 0\n","\n","#             while len(rejected) < 1 and attempts < max_attempts:\n","#                 attempts += 1\n","\n","#                 # Generate a new answer\n","#                 new_answer = generate_answer(combined_prompt)\n","#                 new_answer = clean_generated_text(new_answer)\n","\n","#                 # Avoid duplicate answers\n","#                 if new_answer == output or new_answer in rejected or not new_answer:\n","#                     continue\n","\n","#                 # Preprocess the output and the new_answer\n","#                 output_clean = preprocess_text(output)\n","#                 new_answer_clean = preprocess_text(new_answer)\n","\n","#                 # Calculate similarity score using preprocessed texts\n","#                 similarity_score_WRatio = fuzz.token_set_ratio(output_clean, new_answer_clean)\n","#                 similarity_score_TokenSetRatio = fuzz.token_set_ratio(output_clean, new_answer_clean)\n","\n","#                 if similarity_score_WRatio >= similarity_threshold or similarity_score_TokenSetRatio >= similarity_threshold:\n","#                     # Outputs are similar; skip this candidate\n","#                     continue\n","#                 else:\n","#                     # Outputs are different; add to rejected answers\n","#                     rejected.append(new_answer)\n","\n","#             # For each rejected answer, append to orpo_dataset_dict\n","#             for rej in rejected:\n","#                 orpo_dataset_dict['prompt'].append(prompt)\n","#                 orpo_dataset_dict['chosen'].append(output)\n","#                 orpo_dataset_dict['rejected'].append(rej)\n","\n","#         except Exception as e:\n","#             print(f\"Error processing line {line_num}: {e}\")\n","#             continue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjaY6amWgxQt"},"outputs":[],"source":["# # Print the total number of entries\n","# total_entries = len(orpo_dataset_dict['prompt'])\n","# print(f\"Total entries in orpo_dataset_dict: {total_entries}\")\n","\n","# # Define the number of random samples you want\n","# num_samples = 5\n","\n","# # Adjust the number of samples if there are fewer than 5 entries\n","# if total_entries < num_samples:\n","#     num_samples = total_entries\n","#     print(f\"Only {num_samples} entries available. Displaying all available entries.\")\n","\n","# # Select random unique indices without replacement\n","# random_indices = random.sample(range(total_entries), num_samples)\n","\n","# # Print the selected random entries\n","# for i, idx in enumerate(random_indices, 1):\n","#     print(f\"\\nEntry {i}:\")\n","#     print(f\"Prompt: {orpo_dataset_dict['prompt'][idx]}\")\n","#     print(f\"Chosen (Output from merged dataset): {orpo_dataset_dict['chosen'][idx]}\")\n","#     print(f\"Rejected (Output from default dataset): {orpo_dataset_dict['rejected'][idx]}\")\n","#     print('-' * 50)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OLTHZsagxQt","outputId":"be4941ba-e842-4104-b0b7-b707e6651378"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ORPO dataset saved to ../data/orpo_dataset.json\n"]}],"source":["# # Save to a JSON file\n","# orpo_output_path = Path(data_dir) / 'orpo_dataset.json'\n","\n","# with open(orpo_output_path, 'w', encoding='utf-8') as out_file:\n","#     json.dump(orpo_dataset_dict, out_file, indent=4)\n","\n","# print(f\"\\nORPO dataset saved to {orpo_output_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"m34feoJUjS-Z"},"source":["### Model training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1732047545654,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"bgXnaKFAEe1o","outputId":"ea943a62-1e1a-459c-ef1d-6a00e058a94c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset converted and saved to: ../data/orpo_dataset_from_train_default.txt\n"]}],"source":["# # Path to your JSON dataset\n","# json_file_path = '../data/orpo.json'\n","\n","# # Path to the output TXT file\n","# txt_file_path = '../data/orpo.txt'\n","\n","# # Load the JSON data\n","# with open(json_file_path, 'r', encoding='utf-8') as f:\n","#     data = json.load(f)\n","\n","# # Convert the JSON data to the desired TXT format\n","# txt_content = json.dumps(data, indent=4)  # Indent for better readability\n","\n","# # Write the TXT content to the output file\n","# with open(txt_file_path, 'w', encoding='utf-8') as f:\n","#     f.write(txt_content)\n","\n","# print(f\"Dataset converted and saved to: {txt_file_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qGfqftIPjcId"},"outputs":[],"source":["# def prepare_dataset(dataset_path):\n","#     # Load the dataset from the provided JSON file\n","#     with open(dataset_path, 'r', encoding='utf-8') as f:\n","#         orpo_dataset_dict = json.load(f)\n","#     dataset = Dataset.from_dict(orpo_dataset_dict)\n","#     dataset = dataset.shuffle(seed=42)\n","#     dataset = dataset.train_test_split(test_size=0.05)\n","#     return dataset"]},{"cell_type":"code","source":["# if torch.cuda.get_device_capability()[0] >= 8:\n","#     !pip install -qqq flash-attn\n","#     attn_implementation = \"flash_attention_2\"\n","#     torch_dtype = torch.bfloat16\n","# else:\n","#     attn_implementation = \"eager\"\n","#     torch_dtype = torch.float16"],"metadata":{"id":"0BrV4vvO5_D6","executionInfo":{"status":"ok","timestamp":1732229214112,"user_tz":480,"elapsed":2395,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# torch_dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYXjqmZd5_CT","executionInfo":{"status":"ok","timestamp":1732229223521,"user_tz":480,"elapsed":161,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"2e7db7f0-72ca-4b46-dc9a-de8c62ac5088"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.bfloat16"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Model\n","base_model = \"Qwen/Qwen2.5-0.5B-Instruct\"\n","# new_model = \"qwen2.5-0.5B-Instruct-lora-orpo\"\n","new_model = \"qwen2.5-0.5B-Instruct-orpo\""],"metadata":{"id":"PtzB9O_E543U","executionInfo":{"status":"ok","timestamp":1732229249700,"user_tz":480,"elapsed":207,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["#### LoRA doesn't work well in this hw"],"metadata":{"id":"XVjhibPs25D3"}},{"cell_type":"code","source":["# # QLoRA config\n","# bnb_config = BitsAndBytesConfig(\n","#     load_in_4bit=True,\n","#     bnb_4bit_quant_type=\"nf4\",\n","#     bnb_4bit_compute_dtype=torch_dtype,\n","#     bnb_4bit_use_double_quant=True,\n","# )\n","\n","# # LoRA config\n","# peft_config = LoraConfig(\n","#     task_type=\"CAUSAL_LM\",\n","#     r=16,\n","#     lora_alpha=24,\n","#     lora_dropout=0.05,\n","#     bias=\"none\",\n","#     target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n","# )"],"metadata":{"id":"YhYGFvMC6Jhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(base_model)\n","\n","model = AutoModelForCausalLM.from_pretrained(base_model,\n","                                            #  quantization_config=bnb_config,\n","                                            #  attn_implementation=attn_implementation,\n","                                             device_map=\"auto\")\n","\n","if tokenizer.chat_template is None:\n","    model, tokenizer = setup_chat_format(model, tokenizer) # Only call setup_chat_format if no template exists\n","model = prepare_model_for_kbit_training(model)"],"metadata":{"id":"ZrfiioEEKkrS","executionInfo":{"status":"ok","timestamp":1732229253644,"user_tz":480,"elapsed":1976,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Load ORPO dataset from ../data/orpo.json\n","json_file_path = '../data/orpo.json'\n","\n","with open(json_file_path, 'r', encoding='utf-8') as f:\n","    orpo_dataset_dict = json.load(f)\n","\n","print(orpo_dataset_dict.keys())  # Output: dict_keys(['chosen', 'rejected'])\n","\n","dataset = Dataset.from_dict(orpo_dataset_dict)\n","dataset = dataset.shuffle(seed=42)\n","dataset = dataset.train_test_split(test_size=0.05)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RC2mR_RpLGDd","executionInfo":{"status":"ok","timestamp":1732229265693,"user_tz":480,"elapsed":1892,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"76d40b29-b49e-4a21-a305-725278ea9350"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['chosen', 'rejected'])\n"]}]},{"cell_type":"code","source":["orpo_args = ORPOConfig(\n","    per_device_train_batch_size=4,\n","    max_steps=1000,\n","    learning_rate=8e-5,\n","    gradient_accumulation_steps=1,\n","    logging_steps=10,\n","    eval_steps=500,\n","    output_dir=\"./results/\",\n","    optim=\"rmsprop\",\n","    warmup_steps=150,\n","    bf16=True,\n","    logging_first_step=True,\n","    remove_unused_columns=False,\n","    report_to=\"wandb\"\n",")\n","\n","trainer = ORPOTrainer(\n","    model=model,\n","    args=orpo_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    # peft_config=peft_config,\n",")\n","\n","for param in model.parameters():\n","    param.requires_grad = True\n","\n","trainer.train()\n","trainer.save_model(new_model)"],"metadata":{"id":"33sxE9gT54xP","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a0af8e32a03b4a6fa61cfb846bb84269","8c6aac75f6ab41f6b453e707d9c10f30","3dbad91d74f647c7bc899dfcb9c17221","29cefd01da4a4bcfaa099c86d5909ce9","10796a89cd56454d828b769b72949733","ba5eacaaa7674fb5b51cc246b6c41f1e","4984abd494cd40698a9ce371569c73f7","1bcc56a68fb646a4b586ae6c5d3d82e8","f65ced6e0c734ffab39f9d698a5607e0","e7175d210c4b4dbca7dda81df1ad10a5","f0173b1abd66438fad67b87bb9b83745","af70debd646b478aa5e5ea33618e6d1a","2627281c94b541ee85c02477d9067a35","cad78688904c419192cdc5d568f3e8da","457ce66863b4471ebcd4439549db4492","33deac1176f04ce884010cd6d6fbfa0c","dd7f12d3a7cb4a2294e757809f2c7740","a35525fff35e4c67bda539628b49bb39","38de1e512f7c4fadb150256f6bd429c7","08fc97b29c824b2f89e4468a1f97a576","aa9bb576417e4e3a89f2e3545f9cf52a","94217f24b46145d3a8cd8baec08a3fbf","bd444c05c7ca46b69828bcd6a6397eaf","a31de156afcf4611a2055e55d76a3845","ee62423a90bb4adf8cd79bc02b6a265a","4fa6de4a1c8d4aa4b208bc646ab69e22","0684e6551f00428e86822e68533a3a2b","dbac404a05e545859f685136adc6c5df","3b558638fb6c46d5b476ce850800661f","b1a03ca67bd8453c94643bef989d1566","74b87d148b7f4a2291d8eb6245ccf837","c742746df6c5440194fbb6a40f596455","a4ac60a76abf4ceab307e8167cc0e5a1","0e4df5e381d34b089454a520bc2ca5eb","b9b85589444348af83e9e13b8d3e994e","910fd45c2e374fc08a76d35f4e8be617","f87902166f6b43db946294d080924c0a","668c8b5097604b848f5a0115e696eeae","fd38607dc31f4a9989cf56b0161f89b4","e7cdb530c9744a7c8d95e94a819d1283","ce653642cd1e4fc285d5a4799541cf8f","ac15d8b97e5349d8bc717335d5f3bff1","41b9c4012f214633b85d8168e32c0e88","6cb85fa27afc4e47949e99907c53cdd5","a2ceed7fb24245b2b9c722f0d5626ff8","97035467b628436e97657c6e5f226aca","63e779b5efb24c34ba4f8013d6bbd9c7","326f6a9f41f440ce8f0d6531873120a8","379104fad99a402385935a1e4deff483","6e310c28e1d949e7b7d3a91fdf617be4","d076339ae04c41a5b3915f440dac782a","299582aacbeb4befa4744e2487c9180e","33754a66739f4134bb2af0fbadbd6992","ed5ecb98f1f4480e97bd5cce48d2d3cf","8861604b8a704cdb8a6497c269b7ffb8","824bbd6a4f344b6a9b05e2bdc3c44144","4ba8c662ceb34a7b9f039561e0703006","3f02ef82732d4cb8bf281d238276ceba","dada51ca183c4cdf852aff7a1abbc4d6","1505fb314b5c44449fdb76d8b5d21828","e909d08c73234ddea5eb73fae0ffc856","3b6eb0909efa438c937b96137af52ddc","b9382a3316ed4e66921710f950d9a5ba","3bd4026211d441feb1b41c055933cb85","52814b39c4bc4cde83b90248d47f2afb","eb655d0464a64712b6d96b3e3c18f1a2"]},"executionInfo":{"status":"ok","timestamp":1732230108085,"user_tz":480,"elapsed":829736,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"5f53c932-59dd-4c8e-b917-2288df196dbf"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/orpo_trainer.py:238: UserWarning: `max_length` is not set in the ORPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/orpo_trainer.py:247: UserWarning: `max_prompt_length` is not set in the ORPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/65054 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0af8e32a03b4a6fa61cfb846bb84269"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/65054 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af70debd646b478aa5e5ea33618e6d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/65054 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd444c05c7ca46b69828bcd6a6397eaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3424 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e4df5e381d34b089454a520bc2ca5eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3424 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2ceed7fb24245b2b9c722f0d5626ff8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3424 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824bbd6a4f344b6a9b05e2bdc3c44144"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwenhewangcrane\u001b[0m (\u001b[33mcmpt732\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/frefopt/answer/wandb/run-20241121_225157-wedlxpz8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cmpt732/huggingface/runs/wedlxpz8' target=\"_blank\">./results/</a></strong> to <a href='https://wandb.ai/cmpt732/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cmpt732/huggingface' target=\"_blank\">https://wandb.ai/cmpt732/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cmpt732/huggingface/runs/wedlxpz8' target=\"_blank\">https://wandb.ai/cmpt732/huggingface/runs/wedlxpz8</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 09:38, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.817600</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.094800</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.332300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.788400</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.362500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.405100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.711100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.384200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.867600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.631000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.690700</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>1.873100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.729300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>1.790700</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>1.685300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.666800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.667500</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>1.670500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.780900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>1.636100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.666500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.855900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.785100</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>1.616800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.723900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.660500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.772500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.641400</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.701500</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>1.526000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.726000</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>1.545400</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.697600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.662800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.652000</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.469000</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.684200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>1.597000</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.593800</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.505900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.503700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>1.565700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.645900</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>1.439700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.434300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.472000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.641500</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>1.479600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.449800</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>1.555100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.433600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>1.543100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>1.427000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>1.546800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.486500</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.493900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>1.497200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>1.587900</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>1.550800</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>1.369200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.407500</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>1.494800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>1.402800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>1.424700</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>1.385700</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.589900</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>1.414500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>1.663000</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>1.355900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>1.305000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.489900</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>1.401600</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>1.349100</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>1.342700</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>1.260300</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.391400</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>1.329300</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>1.229000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>1.133500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>1.438900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.473400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>1.366400</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>1.238600</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>1.409900</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>1.369000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>1.372200</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>1.457500</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>1.085000</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>1.312100</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>1.294300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.510400</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>1.283600</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>1.217900</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>1.384100</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>1.198000</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>1.425600</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>1.405900</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>1.235100</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>1.272100</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>1.229200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.143800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"0tHehNfi0tAH"},"source":["### Inference and check our model performance on dev set"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"t2ZaL4dN0E8Y","executionInfo":{"status":"ok","timestamp":1732230108085,"user_tz":480,"elapsed":2,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}}},"outputs":[],"source":["# new_model = 'qwen2.5-0.5B-Instruct-lora-orpo'\n","device = 'cuda'\n","inputfile = os.path.join('..','data', 'input', 'dev.txt')\n","logging.basicConfig(filename='log.txt', filemode='w', level=logging.DEBUG)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26259,"status":"ok","timestamp":1732230134343,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"Vx22waMmvPG5","outputId":"1a300657-9fbb-4247-e476-d6f282ff2fef"},"outputs":[{"output_type":"stream","name":"stderr","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"]}],"source":["%%capture output\n","decode_all(new_model, device, inputfile)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9shBq_z0G7g","executionInfo":{"status":"ok","timestamp":1732230134343,"user_tz":480,"elapsed":6,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"}},"outputId":"54bc4f10-1262-4664-fe39-389e3aea7297"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\"output\": \"-1\"}\n","{\"output\": \"am, am, am, am\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Pizza\\nHamburger\\nSandwich\"}\n","{\"output\": \"True\"}\n","{\"output\": \"True\"}\n","{\"output\": \"True\"}\n","{\"output\": \"NEGATIVE\"}\n","{\"output\": \"complaint\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"C\"}\n","{\"output\": \"POSITIVE\\nNEGATIVE\"}\n","{\"output\": \"1 2 4 3 2 4 1\"}\n","{\"output\": \"not_argumentative\"}\n","{\"output\": \"Yes, the target string can be constructed by concatenating some (or all) of the strings from the list.\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Incorrect\"}\n","{\"output\": \"police\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"1\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Yes, string A is a substring of string B.\"}\n","{\"output\": \"False\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"The opposite of \\\"clamor\\\" is \\\"silent.\\\"\"}\n","{\"output\": \"The word 'cat' is a noun. The word'sky' is an adjective. The word 'blue' is an adjective. The word 'book' is an adjective. The word 'happy' is an adjective.\"}\n","{\"output\": \"fact\"}\n","{\"output\": \"true\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"True\"}\n","{\"output\": \"True\"}\n","{\"output\": \"Alice\"}\n","{\"output\": \"first\"}\n","{\"output\": \"1\"}\n","{\"output\": \"NEGATIVE\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"A\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"1\"}\n","{\"output\": \"Angry\"}\n","{\"output\": \"1\"}\n","{\"output\": \"True\"}\n","{\"output\": \"synonym\"}\n","{\"output\": \"Causal\"}\n","{\"output\": \"a) To create an environment where users can easily use the product or service\\n\\nb) To provide useful information about what the product or service does\\n\\nc) To evaluate how users use the product or service\\n\\nd) To test whether the user's understanding of the product or service is clear\"}\n","{\"output\": \"possible\"}\n","{\"output\": \"dog\"}\n","{\"output\": \"A\"}\n","{\"output\": \"The output should be '1234'.\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"True\"}\n","{\"output\": \"FORMAL\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"True\"}\n","{\"output\": \"B\"}\n","{\"output\": \"There are 12 words in the passage.\"}\n","{\"output\": \"True\"}\n","{\"output\": \"True\"}\n","{\"output\": \"Summary1: After being reported missing, two women were found safe and sound in their car. Summary2: authorities are searching for two missing women who may be in danger.\"}\n","{\"output\": \"Credible\"}\n","{\"output\": \"1\\n1\\n1\"}\n","{\"output\": \"C\"}\n","{\"output\": \"True\"}\n","{\"output\": \"The first sentence is 'I always forget my keys at home.' The second sentence is 'It's been happening since I was a child.' The third sentence is 'My mom would get frustrated with me and lecture me about it.' The fourth sentence is 'But no matter how many times she lectured me, I still forgot my keys.'\"}\n","{\"output\": \"Counterclockwise\"}\n","{\"output\": \"C\"}\n","{\"output\": \"NEGATIVE\"}\n","{\"output\": \"The answer is 3.\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"2, 3, 1, 5\"}\n","{\"output\": \"True\"}\n","{\"output\": \"True\"}\n","{\"output\": \"The connection between the given sentences is 'temporal'.\"}\n","{\"output\": \"unrelated\"}\n","{\"output\": \"1) Put person A on horse B\\n2) Position person A so that their head is level with horse B\\n3) Have person C hold onto the end of rope\\n4) Attach one end of rope D\\n5) Continue to use optionals\"}\n","{\"output\": \"negative\"}\n","{\"output\": \"valid\"}\n","{\"output\": \"stereotype\"}\n","{\"output\": \"1\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"1) GIVING-BIRTH\\n2) GETTING-MARRIED\\n3) DIVORCING\"}\n","{\"output\": \"description\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"1- students\\n2- workers\\n3- families\\n4- immigrants\"}\n","{\"output\": \"conflict-price\"}\n","{\"output\": \"true\"}\n","{\"output\": \"Contoso\"}\n","{\"output\": \"support-response\"}\n","{\"output\": \"Yes\"}\n","{\"output\": \"YES\"}\n","{\"output\": \"The native speaker of a language knows instinctively when a sentence sound wrong but can not say why.\"}\n","{\"output\": \"True\"}\n","{\"output\": \"True\"}\n","{\"output\": \"Sentence1: NEGATIVE\\nSentence2: POSITIVE\"}\n","{\"output\": \"POSITIVE\"}\n","{\"output\": \"Yes\"}\n","\n"]}],"source":["print(output)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732230134343,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"Y7YF7x-70JlI","outputId":"da2fd375-3545-4848-b3b3-0933f02daf0e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3631"]},"metadata":{},"execution_count":17}],"source":["Path(\"output.txt\").write_text(output.stdout)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1732230134343,"user":{"displayName":"Milkistasty","userId":"16252669245058055518"},"user_tz":480},"id":"fjD_Sedn0Ji_","outputId":"de4cdce1-a523-452d-f188-b94d59652f3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Score=55.0000\n"]}],"source":["!python ../output_check.py -t ../data/reference/dev.out -o output.txt"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a0af8e32a03b4a6fa61cfb846bb84269":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c6aac75f6ab41f6b453e707d9c10f30","IPY_MODEL_3dbad91d74f647c7bc899dfcb9c17221","IPY_MODEL_29cefd01da4a4bcfaa099c86d5909ce9"],"layout":"IPY_MODEL_10796a89cd56454d828b769b72949733"}},"8c6aac75f6ab41f6b453e707d9c10f30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba5eacaaa7674fb5b51cc246b6c41f1e","placeholder":"​","style":"IPY_MODEL_4984abd494cd40698a9ce371569c73f7","value":"Map: 100%"}},"3dbad91d74f647c7bc899dfcb9c17221":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bcc56a68fb646a4b586ae6c5d3d82e8","max":65054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f65ced6e0c734ffab39f9d698a5607e0","value":65054}},"29cefd01da4a4bcfaa099c86d5909ce9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7175d210c4b4dbca7dda81df1ad10a5","placeholder":"​","style":"IPY_MODEL_f0173b1abd66438fad67b87bb9b83745","value":" 65054/65054 [00:10&lt;00:00, 6204.62 examples/s]"}},"10796a89cd56454d828b769b72949733":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba5eacaaa7674fb5b51cc246b6c41f1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4984abd494cd40698a9ce371569c73f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bcc56a68fb646a4b586ae6c5d3d82e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f65ced6e0c734ffab39f9d698a5607e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7175d210c4b4dbca7dda81df1ad10a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0173b1abd66438fad67b87bb9b83745":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af70debd646b478aa5e5ea33618e6d1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2627281c94b541ee85c02477d9067a35","IPY_MODEL_cad78688904c419192cdc5d568f3e8da","IPY_MODEL_457ce66863b4471ebcd4439549db4492"],"layout":"IPY_MODEL_33deac1176f04ce884010cd6d6fbfa0c"}},"2627281c94b541ee85c02477d9067a35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd7f12d3a7cb4a2294e757809f2c7740","placeholder":"​","style":"IPY_MODEL_a35525fff35e4c67bda539628b49bb39","value":"Map: 100%"}},"cad78688904c419192cdc5d568f3e8da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38de1e512f7c4fadb150256f6bd429c7","max":65054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08fc97b29c824b2f89e4468a1f97a576","value":65054}},"457ce66863b4471ebcd4439549db4492":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa9bb576417e4e3a89f2e3545f9cf52a","placeholder":"​","style":"IPY_MODEL_94217f24b46145d3a8cd8baec08a3fbf","value":" 65054/65054 [00:22&lt;00:00, 3050.64 examples/s]"}},"33deac1176f04ce884010cd6d6fbfa0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd7f12d3a7cb4a2294e757809f2c7740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35525fff35e4c67bda539628b49bb39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38de1e512f7c4fadb150256f6bd429c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08fc97b29c824b2f89e4468a1f97a576":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa9bb576417e4e3a89f2e3545f9cf52a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94217f24b46145d3a8cd8baec08a3fbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd444c05c7ca46b69828bcd6a6397eaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a31de156afcf4611a2055e55d76a3845","IPY_MODEL_ee62423a90bb4adf8cd79bc02b6a265a","IPY_MODEL_4fa6de4a1c8d4aa4b208bc646ab69e22"],"layout":"IPY_MODEL_0684e6551f00428e86822e68533a3a2b"}},"a31de156afcf4611a2055e55d76a3845":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbac404a05e545859f685136adc6c5df","placeholder":"​","style":"IPY_MODEL_3b558638fb6c46d5b476ce850800661f","value":"Map: 100%"}},"ee62423a90bb4adf8cd79bc02b6a265a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1a03ca67bd8453c94643bef989d1566","max":65054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74b87d148b7f4a2291d8eb6245ccf837","value":65054}},"4fa6de4a1c8d4aa4b208bc646ab69e22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c742746df6c5440194fbb6a40f596455","placeholder":"​","style":"IPY_MODEL_a4ac60a76abf4ceab307e8167cc0e5a1","value":" 65054/65054 [03:12&lt;00:00, 283.83 examples/s]"}},"0684e6551f00428e86822e68533a3a2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbac404a05e545859f685136adc6c5df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b558638fb6c46d5b476ce850800661f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1a03ca67bd8453c94643bef989d1566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74b87d148b7f4a2291d8eb6245ccf837":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c742746df6c5440194fbb6a40f596455":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4ac60a76abf4ceab307e8167cc0e5a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e4df5e381d34b089454a520bc2ca5eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9b85589444348af83e9e13b8d3e994e","IPY_MODEL_910fd45c2e374fc08a76d35f4e8be617","IPY_MODEL_f87902166f6b43db946294d080924c0a"],"layout":"IPY_MODEL_668c8b5097604b848f5a0115e696eeae"}},"b9b85589444348af83e9e13b8d3e994e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd38607dc31f4a9989cf56b0161f89b4","placeholder":"​","style":"IPY_MODEL_e7cdb530c9744a7c8d95e94a819d1283","value":"Map: 100%"}},"910fd45c2e374fc08a76d35f4e8be617":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce653642cd1e4fc285d5a4799541cf8f","max":3424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac15d8b97e5349d8bc717335d5f3bff1","value":3424}},"f87902166f6b43db946294d080924c0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41b9c4012f214633b85d8168e32c0e88","placeholder":"​","style":"IPY_MODEL_6cb85fa27afc4e47949e99907c53cdd5","value":" 3424/3424 [00:00&lt;00:00, 6194.01 examples/s]"}},"668c8b5097604b848f5a0115e696eeae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd38607dc31f4a9989cf56b0161f89b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7cdb530c9744a7c8d95e94a819d1283":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce653642cd1e4fc285d5a4799541cf8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac15d8b97e5349d8bc717335d5f3bff1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41b9c4012f214633b85d8168e32c0e88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cb85fa27afc4e47949e99907c53cdd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2ceed7fb24245b2b9c722f0d5626ff8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97035467b628436e97657c6e5f226aca","IPY_MODEL_63e779b5efb24c34ba4f8013d6bbd9c7","IPY_MODEL_326f6a9f41f440ce8f0d6531873120a8"],"layout":"IPY_MODEL_379104fad99a402385935a1e4deff483"}},"97035467b628436e97657c6e5f226aca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e310c28e1d949e7b7d3a91fdf617be4","placeholder":"​","style":"IPY_MODEL_d076339ae04c41a5b3915f440dac782a","value":"Map: 100%"}},"63e779b5efb24c34ba4f8013d6bbd9c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_299582aacbeb4befa4744e2487c9180e","max":3424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33754a66739f4134bb2af0fbadbd6992","value":3424}},"326f6a9f41f440ce8f0d6531873120a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed5ecb98f1f4480e97bd5cce48d2d3cf","placeholder":"​","style":"IPY_MODEL_8861604b8a704cdb8a6497c269b7ffb8","value":" 3424/3424 [00:01&lt;00:00, 3098.77 examples/s]"}},"379104fad99a402385935a1e4deff483":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e310c28e1d949e7b7d3a91fdf617be4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d076339ae04c41a5b3915f440dac782a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"299582aacbeb4befa4744e2487c9180e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33754a66739f4134bb2af0fbadbd6992":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed5ecb98f1f4480e97bd5cce48d2d3cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8861604b8a704cdb8a6497c269b7ffb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"824bbd6a4f344b6a9b05e2bdc3c44144":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ba8c662ceb34a7b9f039561e0703006","IPY_MODEL_3f02ef82732d4cb8bf281d238276ceba","IPY_MODEL_dada51ca183c4cdf852aff7a1abbc4d6"],"layout":"IPY_MODEL_1505fb314b5c44449fdb76d8b5d21828"}},"4ba8c662ceb34a7b9f039561e0703006":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e909d08c73234ddea5eb73fae0ffc856","placeholder":"​","style":"IPY_MODEL_3b6eb0909efa438c937b96137af52ddc","value":"Map: 100%"}},"3f02ef82732d4cb8bf281d238276ceba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9382a3316ed4e66921710f950d9a5ba","max":3424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bd4026211d441feb1b41c055933cb85","value":3424}},"dada51ca183c4cdf852aff7a1abbc4d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52814b39c4bc4cde83b90248d47f2afb","placeholder":"​","style":"IPY_MODEL_eb655d0464a64712b6d96b3e3c18f1a2","value":" 3424/3424 [00:09&lt;00:00, 374.90 examples/s]"}},"1505fb314b5c44449fdb76d8b5d21828":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e909d08c73234ddea5eb73fae0ffc856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6eb0909efa438c937b96137af52ddc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9382a3316ed4e66921710f950d9a5ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bd4026211d441feb1b41c055933cb85":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52814b39c4bc4cde83b90248d47f2afb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb655d0464a64712b6d96b3e3c18f1a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}